{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 16:08:36.504737: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-23 16:08:36.901269: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-23 16:08:37.583288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"./VLSP2018-SA-train-dev-test/1-VLSP2018-SA-Hotel-train (7-3-2018).txt\",\n",
    "    \"./VLSP2018-SA-train-dev-test/2-VLSP2018-SA-Hotel-dev (7-3-2018).txt\",\n",
    "    \"./VLSP2018-SA-train-dev-test/3-VLSP2018-SA-Hotel-test (8-3-2018).txt\"\n",
    "]\n",
    "\n",
    "file_types = ['train', 'dev', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        line_number = 1\n",
    "        data_list = []\n",
    "\n",
    "        text = None\n",
    "        aspects = []\n",
    "        polarities = []\n",
    "\n",
    "        for line in tqdm(file):\n",
    "            if line == '\\n':\n",
    "                if text and aspects:\n",
    "                    for aspect, polarity in zip(aspects, polarities):\n",
    "                        data_list.append({'text': text, 'aspect_cat': aspect, 'polarity': polarity})\n",
    "                text = None\n",
    "                aspects = []\n",
    "                polarities = []\n",
    "                line_number = 1\n",
    "                continue\n",
    "\n",
    "            if line_number % 2 == 0:\n",
    "                text = line.strip()\n",
    "\n",
    "            if line_number % 3 == 0:\n",
    "                cat_sen = re.findall(r'{(.*?), (.*?)}', line)\n",
    "                for cat, sen in cat_sen:\n",
    "                    aspects.append(cat.strip())\n",
    "                    polarity = sen.strip()\n",
    "                    polarities.append(polarity)\n",
    "\n",
    "            line_number += 1\n",
    "        \n",
    "        # squeeze out the last data\n",
    "        if text and aspects:\n",
    "            for aspect, polarity in zip(aspects, polarities):\n",
    "                data_list.append({'text': text, 'aspect_cat': aspect, 'polarity': polarity})\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(data_list)\n",
    "        df.fillna(0, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "'FACILITIES#CLEANLINESS',\n",
    " 'FACILITIES#COMFORT',\n",
    " 'FACILITIES#DESIGN&FEATURES',\n",
    " 'FACILITIES#GENERAL',\n",
    " 'FACILITIES#MISCELLANEOUS',\n",
    " 'FACILITIES#PRICES',\n",
    " 'FACILITIES#QUALITY',\n",
    " 'FOOD&DRINKS#MISCELLANEOUS',\n",
    " 'FOOD&DRINKS#PRICES',\n",
    " 'FOOD&DRINKS#QUALITY',\n",
    " 'FOOD&DRINKS#STYLE&OPTIONS',\n",
    " 'HOTEL#CLEANLINESS',\n",
    " 'HOTEL#COMFORT',\n",
    " 'HOTEL#DESIGN&FEATURES',\n",
    " 'HOTEL#GENERAL',\n",
    " 'HOTEL#MISCELLANEOUS',\n",
    " 'HOTEL#PRICES',\n",
    " 'HOTEL#QUALITY',\n",
    " 'LOCATION#GENERAL',\n",
    " 'ROOMS#CLEANLINESS',\n",
    " 'ROOMS#COMFORT',\n",
    " 'ROOMS#DESIGN&FEATURES',\n",
    " 'ROOMS#GENERAL',\n",
    " 'ROOMS#MISCELLANEOUS',\n",
    " 'ROOMS#PRICES',\n",
    " 'ROOMS#QUALITY',\n",
    " 'ROOM_AMENITIES#CLEANLINESS',\n",
    " 'ROOM_AMENITIES#COMFORT',\n",
    " 'ROOM_AMENITIES#DESIGN&FEATURES',\n",
    " 'ROOM_AMENITIES#GENERAL',\n",
    " 'ROOM_AMENITIES#MISCELLANEOUS',\n",
    " 'ROOM_AMENITIES#PRICES',\n",
    " 'ROOM_AMENITIES#QUALITY',\n",
    " 'SERVICE#GENERAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{FACILITIES#CLEANLINESS, positive} {FACILITIES#COMFORT, positive} {FACILITIES#DESIGN&FEATURES, positive} {FACILITIES#GENERAL, positive} {FACILITIES#MISCELLANEOUS, positive} {FACILITIES#PRICES, positive} {FACILITIES#QUALITY, positive} {FOOD&DRINKS#MISCELLANEOUS, positive} {FOOD&DRINKS#PRICES, positive} {FOOD&DRINKS#QUALITY, positive} {FOOD&DRINKS#STYLE&OPTIONS, positive} {HOTEL#CLEANLINESS, positive} {HOTEL#COMFORT, positive} {HOTEL#DESIGN&FEATURES, positive} {HOTEL#GENERAL, positive} {HOTEL#MISCELLANEOUS, positive} {HOTEL#PRICES, positive} {HOTEL#QUALITY, positive} {LOCATION#GENERAL, positive} {ROOMS#CLEANLINESS, positive} {ROOMS#COMFORT, positive} {ROOMS#DESIGN&FEATURES, positive} {ROOMS#GENERAL, positive} {ROOMS#MISCELLANEOUS, positive} {ROOMS#PRICES, positive} {ROOMS#QUALITY, positive} {ROOM_AMENITIES#CLEANLINESS, positive} {ROOM_AMENITIES#COMFORT, positive} {ROOM_AMENITIES#DESIGN&FEATURES, positive} {ROOM_AMENITIES#GENERAL, positive} {ROOM_AMENITIES#MISCELLANEOUS, positive} {ROOM_AMENITIES#PRICES, positive} {ROOM_AMENITIES#QUALITY, positive} {SERVICE#GENERAL, positive} "
     ]
    }
   ],
   "source": [
    "for value in column_names:\n",
    "    print(\"{{{value}, positive}}\".format(value=value), end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FACILITIES#CLEANLINESS': 0.0,\n",
       " 'FACILITIES#COMFORT': 0.0,\n",
       " 'FACILITIES#DESIGN&FEATURES': 0.0,\n",
       " 'FACILITIES#GENERAL': 0.0,\n",
       " 'FACILITIES#MISCELLANEOUS': 0.0,\n",
       " 'FACILITIES#PRICES': 0.0,\n",
       " 'FACILITIES#QUALITY': 0.0,\n",
       " 'FOOD&DRINKS#MISCELLANEOUS': 0.0,\n",
       " 'FOOD&DRINKS#PRICES': 0.0,\n",
       " 'FOOD&DRINKS#QUALITY': 0.0,\n",
       " 'FOOD&DRINKS#STYLE&OPTIONS': 0.0,\n",
       " 'HOTEL#CLEANLINESS': 0.0,\n",
       " 'HOTEL#COMFORT': 0.0,\n",
       " 'HOTEL#DESIGN&FEATURES': 0.0,\n",
       " 'HOTEL#GENERAL': 0.0,\n",
       " 'HOTEL#MISCELLANEOUS': 0.0,\n",
       " 'HOTEL#PRICES': 0.0,\n",
       " 'HOTEL#QUALITY': 0.0,\n",
       " 'LOCATION#GENERAL': 0.0,\n",
       " 'ROOMS#CLEANLINESS': 0.0,\n",
       " 'ROOMS#COMFORT': 0.0,\n",
       " 'ROOMS#DESIGN&FEATURES': 0.0,\n",
       " 'ROOMS#GENERAL': 0.0,\n",
       " 'ROOMS#MISCELLANEOUS': 0.0,\n",
       " 'ROOMS#PRICES': 0.0,\n",
       " 'ROOMS#QUALITY': 0.0,\n",
       " 'ROOM_AMENITIES#CLEANLINESS': 0.0,\n",
       " 'ROOM_AMENITIES#COMFORT': 0.0,\n",
       " 'ROOM_AMENITIES#DESIGN&FEATURES': 0.0,\n",
       " 'ROOM_AMENITIES#GENERAL': 0.0,\n",
       " 'ROOM_AMENITIES#MISCELLANEOUS': 0.0,\n",
       " 'ROOM_AMENITIES#PRICES': 0.0,\n",
       " 'ROOM_AMENITIES#QUALITY': 0.0,\n",
       " 'SERVICE#GENERAL': 0.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dict = {column: 0.0 for column in column_names}\n",
    "column_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aspect_data(file_path):\n",
    "    from collections import OrderedDict\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = None\n",
    "        # copy dict\n",
    "        dup = dict(column_dict)\n",
    "        flag = True\n",
    "        data_list = []\n",
    "        for line in tqdm(file):\n",
    "\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            elif line.startswith('{'):\n",
    "                cat_sen = re.findall(r'{(.*?), (.*?)}', line)\n",
    "                for cat, sen in cat_sen:\n",
    "                    if sen.strip() == \"negative\":\n",
    "                        dup[cat] = 1.0\n",
    "                    elif sen.strip() == \"neutral\":\n",
    "                        dup[cat] = 1.0\n",
    "                    elif sen.strip() == \"positive\":\n",
    "                        dup[cat] = 1.0\n",
    "                    else:\n",
    "                        dup[cat] = 0\n",
    "                flag = False\n",
    "            else:\n",
    "                text = line\n",
    "            \n",
    "            if text is not None and not flag:\n",
    "                tmp_dict = OrderedDict([('text', text)] + list(dup.items()))\n",
    "                data_list.append(tmp_dict)\n",
    "                dup = dict(column_dict)\n",
    "                tmp_dict = None\n",
    "                text = None \n",
    "                flag = True\n",
    "                \n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12003it [00:00, 763138.26it/s]\n",
      "7999it [00:00, 1123697.55it/s]\n",
      "2399it [00:00, 956294.93it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"sentiment_data\"):\n",
    "    os.mkdir(\"sentiment_data\")\n",
    "for idx, file_path in enumerate(file_paths):\n",
    "    df = create_sentiment_data(file_path)\n",
    "    df.to_csv('./sentiment_data/{}_hotel_reviews.csv'.format(file_types[idx]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12003it [00:00, 530184.83it/s]\n",
      "7999it [00:00, 609505.64it/s]\n",
      "2399it [00:00, 567520.32it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"aspect_data\"):\n",
    "    os.mkdir(\"aspect_data\")\n",
    "for idx, file_path in enumerate(file_paths):\n",
    "    df = create_aspect_data(file_path)\n",
    "    df.to_csv('./aspect_data/{}_hotel_reviews.csv'.format(file_types[idx]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 09:54:00.021814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:54:00.022535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:54:00.022610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_cat</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13949</th>\n",
       "      <td>Bữa sáng không thay đổi, không có TV, không dọ...</td>\n",
       "      <td>FOOD&amp;DRINKS#STYLE&amp;OPTIONS</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13950</th>\n",
       "      <td>Bữa sáng không thay đổi, không có TV, không dọ...</td>\n",
       "      <td>ROOM_AMENITIES#DESIGN&amp;FEATURES</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13951</th>\n",
       "      <td>Bữa sáng không thay đổi, không có TV, không dọ...</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13952</th>\n",
       "      <td>Bữa sáng không thay đổi, không có TV, không dọ...</td>\n",
       "      <td>ROOMS#CLEANLINESS</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13953</th>\n",
       "      <td>Bữa sáng không thay đổi, không có TV, không dọ...</td>\n",
       "      <td>ROOM_AMENITIES#PRICES</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "13949  Bữa sáng không thay đổi, không có TV, không dọ...   \n",
       "13950  Bữa sáng không thay đổi, không có TV, không dọ...   \n",
       "13951  Bữa sáng không thay đổi, không có TV, không dọ...   \n",
       "13952  Bữa sáng không thay đổi, không có TV, không dọ...   \n",
       "13953  Bữa sáng không thay đổi, không có TV, không dọ...   \n",
       "\n",
       "                           aspect_cat  polarity  \n",
       "13949       FOOD&DRINKS#STYLE&OPTIONS  negative  \n",
       "13950  ROOM_AMENITIES#DESIGN&FEATURES  negative  \n",
       "13951                 SERVICE#GENERAL  negative  \n",
       "13952               ROOMS#CLEANLINESS  negative  \n",
       "13953           ROOM_AMENITIES#PRICES  negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./sentiment_data/train_hotel_reviews.csv')\n",
    "df_val = pd.read_csv('./sentiment_data/dev_hotel_reviews.csv')\n",
    "df_test = pd.read_csv('./sentiment_data/test_hotel_reviews.csv')\n",
    "\n",
    "df_aspect_train = pd.read_csv('./aspect_data/train_hotel_reviews.csv')\n",
    "df_aspect_val = pd.read_csv('./aspect_data/dev_hotel_reviews.csv')\n",
    "df_aspect_test = pd.read_csv('./aspect_data/test_hotel_reviews.csv')\n",
    "\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>FACILITIES#CLEANLINESS</th>\n",
       "      <th>FACILITIES#COMFORT</th>\n",
       "      <th>FACILITIES#DESIGN&amp;FEATURES</th>\n",
       "      <th>FACILITIES#GENERAL</th>\n",
       "      <th>FACILITIES#MISCELLANEOUS</th>\n",
       "      <th>FACILITIES#PRICES</th>\n",
       "      <th>FACILITIES#QUALITY</th>\n",
       "      <th>FOOD&amp;DRINKS#MISCELLANEOUS</th>\n",
       "      <th>FOOD&amp;DRINKS#PRICES</th>\n",
       "      <th>...</th>\n",
       "      <th>ROOMS#PRICES</th>\n",
       "      <th>ROOMS#QUALITY</th>\n",
       "      <th>ROOM_AMENITIES#CLEANLINESS</th>\n",
       "      <th>ROOM_AMENITIES#COMFORT</th>\n",
       "      <th>ROOM_AMENITIES#DESIGN&amp;FEATURES</th>\n",
       "      <th>ROOM_AMENITIES#GENERAL</th>\n",
       "      <th>ROOM_AMENITIES#MISCELLANEOUS</th>\n",
       "      <th>ROOM_AMENITIES#PRICES</th>\n",
       "      <th>ROOM_AMENITIES#QUALITY</th>\n",
       "      <th>SERVICE#GENERAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rộng rãi KS mới nhưng rất vắng. Các dịch vụ ch...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Địa điểm thuận tiện, trong vòng bán kính 1,5km...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phục vụ, view đẹp, vị trí</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thuận tiện , sạch sẽ , vui vẻ hài lòng</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vị trí đẹp; Có quán bar view đẹp; Nhân viên th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  FACILITIES#CLEANLINESS  \\\n",
       "0  Rộng rãi KS mới nhưng rất vắng. Các dịch vụ ch...                     0.0   \n",
       "1  Địa điểm thuận tiện, trong vòng bán kính 1,5km...                     0.0   \n",
       "2                          Phục vụ, view đẹp, vị trí                     0.0   \n",
       "3             thuận tiện , sạch sẽ , vui vẻ hài lòng                     0.0   \n",
       "4  Vị trí đẹp; Có quán bar view đẹp; Nhân viên th...                     0.0   \n",
       "\n",
       "   FACILITIES#COMFORT  FACILITIES#DESIGN&FEATURES  FACILITIES#GENERAL  \\\n",
       "0                 0.0                         0.0                 0.0   \n",
       "1                 0.0                         0.0                 0.0   \n",
       "2                 0.0                         0.0                 0.0   \n",
       "3                 0.0                         0.0                 0.0   \n",
       "4                 0.0                         0.0                 1.0   \n",
       "\n",
       "   FACILITIES#MISCELLANEOUS  FACILITIES#PRICES  FACILITIES#QUALITY  \\\n",
       "0                       0.0                0.0                 0.0   \n",
       "1                       0.0                0.0                 0.0   \n",
       "2                       0.0                0.0                 0.0   \n",
       "3                       0.0                0.0                 0.0   \n",
       "4                       0.0                0.0                 0.0   \n",
       "\n",
       "   FOOD&DRINKS#MISCELLANEOUS  FOOD&DRINKS#PRICES  ...  ROOMS#PRICES  \\\n",
       "0                        0.0                 0.0  ...           0.0   \n",
       "1                        0.0                 0.0  ...           0.0   \n",
       "2                        0.0                 0.0  ...           0.0   \n",
       "3                        0.0                 0.0  ...           0.0   \n",
       "4                        0.0                 0.0  ...           0.0   \n",
       "\n",
       "   ROOMS#QUALITY  ROOM_AMENITIES#CLEANLINESS  ROOM_AMENITIES#COMFORT  \\\n",
       "0            0.0                         0.0                     0.0   \n",
       "1            0.0                         0.0                     0.0   \n",
       "2            0.0                         0.0                     0.0   \n",
       "3            0.0                         0.0                     0.0   \n",
       "4            0.0                         0.0                     0.0   \n",
       "\n",
       "   ROOM_AMENITIES#DESIGN&FEATURES  ROOM_AMENITIES#GENERAL  \\\n",
       "0                             0.0                     0.0   \n",
       "1                             0.0                     0.0   \n",
       "2                             0.0                     0.0   \n",
       "3                             0.0                     0.0   \n",
       "4                             0.0                     0.0   \n",
       "\n",
       "   ROOM_AMENITIES#MISCELLANEOUS  ROOM_AMENITIES#PRICES  \\\n",
       "0                           0.0                    0.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    0.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   ROOM_AMENITIES#QUALITY  SERVICE#GENERAL  \n",
       "0                     0.0              0.0  \n",
       "1                     0.0              0.0  \n",
       "2                     0.0              1.0  \n",
       "3                     0.0              1.0  \n",
       "4                     0.0              1.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aspect_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_cat</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13954</td>\n",
       "      <td>13954</td>\n",
       "      <td>13954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2949</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Gia đình tôi rất hài lòng khi ở tại khách sạn....</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>44</td>\n",
       "      <td>1913</td>\n",
       "      <td>10229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       aspect_cat  \\\n",
       "count                                               13954            13954   \n",
       "unique                                               2949               34   \n",
       "top     Gia đình tôi rất hài lòng khi ở tại khách sạn....  SERVICE#GENERAL   \n",
       "freq                                                   44             1913   \n",
       "\n",
       "        polarity  \n",
       "count      13954  \n",
       "unique         3  \n",
       "top     positive  \n",
       "freq       10229  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2949, 34, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.text.nunique(), df_train.aspect_cat.nunique(), df_train.polarity.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aspect_cat\n",
       "SERVICE#GENERAL                   1913\n",
       "HOTEL#GENERAL                     1282\n",
       "LOCATION#GENERAL                  1196\n",
       "HOTEL#COMFORT                     1139\n",
       "ROOMS#DESIGN&FEATURES              916\n",
       "HOTEL#DESIGN&FEATURES              877\n",
       "FOOD&DRINKS#QUALITY                672\n",
       "ROOMS#CLEANLINESS                  659\n",
       "FOOD&DRINKS#STYLE&OPTIONS          570\n",
       "FACILITIES#DESIGN&FEATURES         525\n",
       "HOTEL#PRICES                       496\n",
       "ROOMS#COMFORT                      434\n",
       "ROOM_AMENITIES#DESIGN&FEATURES     355\n",
       "HOTEL#CLEANLINESS                  348\n",
       "ROOMS#GENERAL                      256\n",
       "HOTEL#QUALITY                      246\n",
       "ROOM_AMENITIES#QUALITY             239\n",
       "FACILITIES#GENERAL                 219\n",
       "ROOM_AMENITIES#GENERAL             216\n",
       "FACILITIES#QUALITY                 208\n",
       "ROOMS#PRICES                       196\n",
       "FACILITIES#CLEANLINESS             172\n",
       "ROOMS#QUALITY                      164\n",
       "FACILITIES#COMFORT                 132\n",
       "FOOD&DRINKS#PRICES                 118\n",
       "HOTEL#MISCELLANEOUS                108\n",
       "ROOM_AMENITIES#COMFORT             100\n",
       "ROOM_AMENITIES#CLEANLINESS          89\n",
       "FACILITIES#PRICES                   53\n",
       "FACILITIES#MISCELLANEOUS            33\n",
       "FOOD&DRINKS#MISCELLANEOUS           13\n",
       "ROOMS#MISCELLANEOUS                  6\n",
       "ROOM_AMENITIES#MISCELLANEOUS         3\n",
       "ROOM_AMENITIES#PRICES                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.aspect_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "positive    10229\n",
       "negative     3155\n",
       "neutral       570\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nội thất phòng đầy đủ và được chuẩn bị tốt. Có dọn phòng hàng ngày. Nhân viên dọn dẹp và lễ tân nhiệt tình. Vị trí gần biển. Phòng hơi nhỏ. Khách sạn có tầm nhìn ra không được đẹp lắm. Tiền thuê xe do khách san liên hệ hơi mắc và không có nhiều xe để chọn. Nước chảy yếu ở vòi sen. Buổi sáng hơi ít món.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.text.iloc[1584]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hiếu\" == \"hiếu\", \"hiếu\" == \"hiêú\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source code: https://colab.research.google.com/github/nguyenvanhieuvn/text-classification-tutorial/blob/master/text_classification_tutorial.ipynb#scrollTo=Koy7eu1dMwxn\n",
    "import regex as re\n",
    "\n",
    "uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
    "unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
    "\n",
    "def loaddicchar():\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "        '|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    "dicchar = loaddicchar()\n",
    "\n",
    "# Hàm chuyển Unicode dựng sẵn về Unicde tổ hợp (phổ biến hơn)\n",
    "def convert_unicode(txt):\n",
    "    return re.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar[x.group()], txt)\n",
    "\n",
    "bang_nguyen_am = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
    "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
    "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
    "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
    "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
    "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
    "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
    "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
    "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
    "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
    "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
    "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
    "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
    "\n",
    "nguyen_am_to_ids = {}\n",
    "\n",
    "for i in range(len(bang_nguyen_am)):\n",
    "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
    "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
    "\n",
    "def chuan_hoa_dau_tu_tieng_viet(word):\n",
    "    if not is_valid_vietnam_word(word):\n",
    "        return word\n",
    "\n",
    "    chars = list(word)\n",
    "    dau_cau = 0\n",
    "    nguyen_am_index = []\n",
    "    qu_or_gi = False\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x == -1:\n",
    "            continue\n",
    "        elif x == 9:  # check qu\n",
    "            if index != 0 and chars[index - 1] == 'q':\n",
    "                chars[index] = 'u'\n",
    "                qu_or_gi = True\n",
    "        elif x == 5:  # check gi\n",
    "            if index != 0 and chars[index - 1] == 'g':\n",
    "                chars[index] = 'i'\n",
    "                qu_or_gi = True\n",
    "        if y != 0:\n",
    "            dau_cau = y\n",
    "            chars[index] = bang_nguyen_am[x][0]\n",
    "        if not qu_or_gi or index != 1:\n",
    "            nguyen_am_index.append(index)\n",
    "    if len(nguyen_am_index) < 2:\n",
    "        if qu_or_gi:\n",
    "            if len(chars) == 2:\n",
    "                x, y = nguyen_am_to_ids.get(chars[1])\n",
    "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
    "            else:\n",
    "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
    "                if x != -1:\n",
    "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
    "                else:\n",
    "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
    "            return ''.join(chars)\n",
    "        return word\n",
    "\n",
    "    for index in nguyen_am_index:\n",
    "        x, y = nguyen_am_to_ids[chars[index]]\n",
    "        if x == 4 or x == 8:  # ê, ơ\n",
    "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
    "            # for index2 in nguyen_am_index:\n",
    "            #     if index2 != index:\n",
    "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
    "            #         chars[index2] = bang_nguyen_am[x][0]\n",
    "            return ''.join(chars)\n",
    "\n",
    "    if len(nguyen_am_index) == 2:\n",
    "        if nguyen_am_index[-1] == len(chars) - 1:\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
    "        else:\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "    else:\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
    "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
    "    return ''.join(chars)\n",
    "\n",
    "\n",
    "def is_valid_vietnam_word(word):\n",
    "    chars = list(word)\n",
    "    nguyen_am_index = -1\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x != -1:\n",
    "            if nguyen_am_index == -1:\n",
    "                nguyen_am_index = index\n",
    "            else:\n",
    "                if index - nguyen_am_index != 1:\n",
    "                    return False\n",
    "                nguyen_am_index = index\n",
    "    return True\n",
    "\n",
    "\n",
    "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
    "    \"\"\"\n",
    "        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n",
    "        :param sentence:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    for index, word in enumerate(words):\n",
    "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
    "        # print(cw)\n",
    "        if len(cw) == 3:\n",
    "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
    "        words[index] = ''.join(cw)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_html(txt):\n",
    "    return re.sub(r'<[^>]*>', '', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-23 09:54:00--  https://gist.githubusercontent.com/nguyenvanhieuvn/7d9441c10b3c2739499fc5a4d9ea06fb/raw/df939245b3e841b62af115be4dcb3516dadc9fc5/teencode.txt\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5656 (5,5K) [text/plain]\n",
      "Saving to: ‘teencode.txt’\n",
      "\n",
      "teencode.txt        100%[===================>]   5,52K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-10-23 09:54:00 (6,58 MB/s) - ‘teencode.txt’ saved [5656/5656]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://gist.githubusercontent.com/nguyenvanhieuvn/7d9441c10b3c2739499fc5a4d9ea06fb/raw/df939245b3e841b62af115be4dcb3516dadc9fc5/teencode.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "replace_list = {\n",
    "    'ô kêi': 'ok', 'okie': 'ok', 'o kê': 'ok', 'okey': 'ok', 'ôkê': 'ok', 'oki': 'ok', 'oke': 'ok', 'okay': 'ok', 'okê': 'ok',\n",
    "    'tks': 'cảm ơn', 'thks': 'cảm ơn', 'thanks': 'cảm ơn', 'ths': 'cảm ơn', 'thank': 'cảm ơn',\n",
    "    'kg': 'không', 'not': 'không', 'k': 'không', 'kh': 'không', 'kô': 'không', 'hok': 'không', 'ko': 'không', 'khong': 'không', 'kp': 'không phải',\n",
    "    'he he': 'tích cực', 'hehe': 'tích cực', 'hihi': 'tích cực', 'haha': 'tích cực', 'hjhj': 'tích cực', 'thick': 'tích cực',\n",
    "    'lol': 'tiêu cực', 'cc': 'tiêu cực', 'huhu': 'tiêu cực', 'cute': 'dễ thương',\n",
    "     \n",
    "    'sz': 'cỡ', 'size': 'cỡ', \n",
    "    'wa': 'quá', 'wá': 'quá', 'qá': 'quá', \n",
    "    'đx': 'được', 'dk': 'được', 'dc': 'được', 'đk': 'được', 'đc': 'được', \n",
    "    'vs': 'với', 'j': 'gì', '“': ' ', 'time': 'thời gian', 'm': 'mình', 'mik': 'mình', 'r': 'rồi', 'bjo': 'bao giờ', 'very': 'rất',\n",
    "\n",
    "    'authentic': 'chuẩn chính hãng', 'aut': 'chuẩn chính hãng', 'auth': 'chuẩn chính hãng', 'date': 'hạn sử dụng', 'hsd': 'hạn sử dụng', \n",
    "    'store': 'cửa hàng', 'sop': 'cửa hàng', 'shopE': 'cửa hàng', 'shop': 'cửa hàng', \n",
    "    'sp': 'sản phẩm', 'product': 'sản phẩm', 'hàg': 'hàng', \n",
    "    'ship': 'giao hàng', 'delivery': 'giao hàng', 'síp': 'giao hàng', 'order': 'đặt hàng',\n",
    "\n",
    "    'gud': 'tốt', 'wel done': 'tốt', 'good': 'tốt', 'gút': 'tốt', 'tot': 'tốt', 'nice': 'tốt', 'perfect': 'rất tốt', \n",
    "    'quality': 'chất lượng', 'chất lg': 'chất lượng', 'chat': 'chất', 'excelent': 'hoàn hảo', 'bt': 'bình thường',\n",
    "    'sad': 'tệ', 'por': 'tệ', 'poor': 'tệ', 'bad': 'tệ', \n",
    "    'beautiful': 'đẹp tuyệt vời', 'dep': 'đẹp', \n",
    "    'xau': 'xấu', 'sấu': 'xấu', \n",
    "     \n",
    "    'thik': 'thích', 'iu': 'yêu', 'fake': 'giả mạo', \n",
    "    'quickly': 'nhanh', 'quick': 'nhanh', 'fast': 'nhanh',\n",
    "    'fresh': 'tươi', 'delicious': 'ngon',\n",
    "\n",
    "    'dt': 'điện thoại', 'fb': 'facebook', 'face': 'facebook', 'ks': 'khách sạn', 'nv': 'nhân viên',\n",
    "    'nt': 'nhắn tin', 'ib': 'nhắn tin', 'tl': 'trả lời', 'trl': 'trả lời', 'rep': 'trả lời',\n",
    "    'fback': 'feedback', 'fedback': 'feedback',\n",
    "    'sd': 'sử dụng', 'sài': 'xài', \n",
    "\n",
    "    '^_^': 'tích cực', ':)': 'tích cực', ':(': 'tiêu cực',\n",
    "    '❤️': 'tích cực', '👍': 'tích cực', '🎉': 'tích cực', '😀': 'tích cực', '😍': 'tích cực', '😂': 'tích cực', '🤗': 'tích cực', '😙': 'tích cực', '🙂': 'tích cực', \n",
    "    '😔': 'tiêu cực', '😓': 'tiêu cực', \n",
    "    '⭐': 'star', '*': 'star', '🌟': 'star',\n",
    "}\n",
    "\n",
    "with open('teencode.txt', encoding='utf-8') as f:\n",
    "    for pair in f.readlines():\n",
    "        key, value = pair.split('\\t')\n",
    "        replace_list[key] = value.strip()\n",
    "\n",
    "\n",
    "def normalize_acronyms(text):\n",
    "    words = []\n",
    "    for word in text.strip().split():\n",
    "        # word = word.strip(string.punctuation)\n",
    "        if word.lower() not in replace_list.keys(): words.append(word)\n",
    "        else: words.append(replace_list[word.lower()])\n",
    "    return emoji.demojize(' '.join(words)) # Remove Emojis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"Nhân viên nhiệt tình Phòng sạch sẽ Nếu có dịp sẽ quay lại 👍👍\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_space_between_emojis(sentence):\n",
    "    result = []\n",
    "    for i in range(len(sentence) - 1):\n",
    "        result.append(sentence[i])\n",
    "        if emoji.emoji_count(sentence[i:i+2]) == 2:\n",
    "            result.append(' ')\n",
    "    result.append(sentence[-1])\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nhân viên nhiệt tình Phòng sạch sẽ Nếu có dịp sẽ quay lại :thumbs_up::thumbs_up:'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_acronyms(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nhân viên nhiệt tình Phòng sạch sẽ Nếu có dịp sẽ quay lại tích cực tích cực'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_acronyms(insert_space_between_emojis(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nhân viên nhiệt tình Phòng sạch sẽ Nếu có dịp sẽ quay lại:thumbs_up: tích cực'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_acronyms(insert_space_between_emojis(\"Nhân viên nhiệt tình Phòng sạch sẽ Nếu có dịp sẽ quay lại👍👍\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/trungtv/pyvi\n",
    "from pyvi import ViTokenizer, ViPosTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-23 09:54:00--  https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords-dash.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20475 (20K) [text/plain]\n",
      "Saving to: ‘vietnamese-stopwords-dash.txt’\n",
      "\n",
      "vietnamese-stopword 100%[===================>]  20,00K  --.-KB/s    in 0,005s  \n",
      "\n",
      "2023-10-23 09:54:01 (3,57 MB/s) - ‘vietnamese-stopwords-dash.txt’ saved [20475/20475]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords-dash.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    with open('./vietnamese-stopwords-dash.txt', encoding='utf-8') as f:\n",
    "        stopwords = set([w.strip()for w in f])\n",
    "        \n",
    "    words = text.split()\n",
    "    filtered_words = [w for w in words if w not in stopwords]\n",
    "    \n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(document):\n",
    "    document = normalize_acronyms(insert_space_between_emojis(document))\n",
    "    # xóa html code\n",
    "    document = remove_html(document)\n",
    "    # chuẩn hóa unicode\n",
    "    document = convert_unicode(document)\n",
    "    # chuẩn hóa cách gõ dấu tiếng Việt\n",
    "    document = chuan_hoa_dau_cau_tieng_viet(document)\n",
    "    # tách từ\n",
    "    document = ViTokenizer.tokenize(document)\n",
    "    # đưa về lower\n",
    "    document = document.lower()\n",
    "    # xóa các ký tự không cần thiết\n",
    "    document = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',document)\n",
    "    # xóa khoảng trắng thừa\n",
    "    document = re.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nhân_viên nhiệt_tình phòng sạch_sẽ nếu có dịp sẽ quay lại tích_cực tích_cực'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = text_preprocess(sample)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13954/13954 [00:17<00:00, 806.46it/s] \n",
      "100%|██████████| 7111/7111 [00:05<00:00, 1390.05it/s]\n",
      "100%|██████████| 2584/2584 [00:02<00:00, 1211.92it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_train['cleaned_text'] = df_train.text.progress_apply(text_preprocess)\n",
    "df_val['cleaned_text'] = df_val.text.progress_apply(text_preprocess)\n",
    "df_test['cleaned_text'] = df_test.text.progress_apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:03<00:00, 971.81it/s] \n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1837.31it/s]\n",
      "100%|██████████| 600/600 [00:00<00:00, 1475.54it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_aspect_train['cleaned_text'] = df_aspect_train.text.progress_apply(text_preprocess)\n",
    "df_aspect_val['cleaned_text'] = df_aspect_val.text.progress_apply(text_preprocess)\n",
    "df_aspect_test['cleaned_text'] = df_aspect_test.text.progress_apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'co view huong ho tay sach se nhan vien tan tinh'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.cleaned_text.iloc[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aspect term extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aspect_terms(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    doc = ViPosTagger.postagging(text)\n",
    "    aspect_terms = []\n",
    "    #N - Common noun Nc - Noun Classifier Ny - Noun abbreviation Nu - Unit noun Np - Proper noun X - Unknown\n",
    "    aspect_pos_patterns = [\"N\", \"Np\", \"Nc\", \"Ny\", \"X\", \"V\", \"A\"]\n",
    "    \n",
    "    for idx, pos_tag in enumerate(doc[1]):\n",
    "        if pos_tag in aspect_pos_patterns:\n",
    "            aspect_terms.append(doc[0][idx])\n",
    "            \n",
    "    return ' '.join(aspect_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nhân_viên nhiệt_tình phòng sạch_sẽ có dịp quay tích_cực tích_cực'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_aspect_terms(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:00<00:00, 3237.33it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 6645.48it/s]\n",
      "100%|██████████| 600/600 [00:00<00:00, 5129.85it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_aspect_train['aspect_term'] = df_aspect_train.cleaned_text.progress_apply(extract_aspect_terms)\n",
    "df_aspect_val['aspect_term'] = df_aspect_val.cleaned_text.progress_apply(extract_aspect_terms)\n",
    "df_aspect_test['aspect_term'] = df_aspect_test.cleaned_text.progress_apply(extract_aspect_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aspect category detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Phòng đẹp , sạch sẽ và gần biển . Nhân viên dễ thương . Phòng không có view biển như lúc đặt , Tv hay mất cáp .\"\n",
    "correct_aspect_cat = \"ROOMS#DESIGN&FEATURES, ROOMS#CLEANLINESS, LOCATION#GENERAL, SERVICE#GENERAL, ROOMS#GENERAL, ROOM_AMENITIES#DESIGN&FEATURES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_column_names(binary_list, column_names):\n",
    "    for i, value in enumerate(binary_list):\n",
    "        if value == 1:\n",
    "            print(column_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def multi_label_metrics(true_labels, predicted_labels):\n",
    "    # Calculate Hamming loss\n",
    "    hamming_loss_value = hamming_loss(true_labels, predicted_labels)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score using micro and macro averaging\n",
    "    precision_micro = precision_score(true_labels, predicted_labels, average='micro')\n",
    "    recall_micro = recall_score(true_labels, predicted_labels, average='micro')\n",
    "    f1_micro = f1_score(true_labels, predicted_labels, average='micro')\n",
    "\n",
    "    precision_macro = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    recall_macro = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    f1_macro = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        \"Hamming Loss\": hamming_loss_value,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Micro)\": precision_micro,\n",
    "        \"Recall (Micro)\": recall_micro,\n",
    "        \"F1 Score (Micro)\": f1_micro,\n",
    "        \"Precision (Macro)\": precision_macro,\n",
    "        \"Recall (Macro)\": recall_macro,\n",
    "        \"F1 Score (Macro)\": f1_macro\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aspect_train_base = df_aspect_train.drop(columns=['text', 'cleaned_text'])\n",
    "df_aspect_val_base = df_aspect_val.drop(columns=['text', 'cleaned_text'])\n",
    "df_aspect_test_base = df_aspect_test.drop(columns=['text', 'cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACILITIES#CLEANLINESS</th>\n",
       "      <th>FACILITIES#COMFORT</th>\n",
       "      <th>FACILITIES#DESIGN&amp;FEATURES</th>\n",
       "      <th>FACILITIES#GENERAL</th>\n",
       "      <th>FACILITIES#MISCELLANEOUS</th>\n",
       "      <th>FACILITIES#PRICES</th>\n",
       "      <th>FACILITIES#QUALITY</th>\n",
       "      <th>FOOD&amp;DRINKS#MISCELLANEOUS</th>\n",
       "      <th>FOOD&amp;DRINKS#PRICES</th>\n",
       "      <th>FOOD&amp;DRINKS#QUALITY</th>\n",
       "      <th>...</th>\n",
       "      <th>ROOMS#QUALITY</th>\n",
       "      <th>ROOM_AMENITIES#CLEANLINESS</th>\n",
       "      <th>ROOM_AMENITIES#COMFORT</th>\n",
       "      <th>ROOM_AMENITIES#DESIGN&amp;FEATURES</th>\n",
       "      <th>ROOM_AMENITIES#GENERAL</th>\n",
       "      <th>ROOM_AMENITIES#MISCELLANEOUS</th>\n",
       "      <th>ROOM_AMENITIES#PRICES</th>\n",
       "      <th>ROOM_AMENITIES#QUALITY</th>\n",
       "      <th>SERVICE#GENERAL</th>\n",
       "      <th>aspect_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rộng_rãi khách_sạn vắng dịch_vụ chất_lượng cao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>địa_điểm thuận_tiện vòng bán_kính nhiều quán ă...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>phục_vụ view đẹp vị_trí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thuận_tiện sạch_sẽ vui_vẻ hài_lòng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>vị_trí đẹp có quán bar view đẹp nhân_viên thân...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FACILITIES#CLEANLINESS  FACILITIES#COMFORT  FACILITIES#DESIGN&FEATURES  \\\n",
       "0                     0.0                 0.0                         0.0   \n",
       "1                     0.0                 0.0                         0.0   \n",
       "2                     0.0                 0.0                         0.0   \n",
       "3                     0.0                 0.0                         0.0   \n",
       "4                     0.0                 0.0                         0.0   \n",
       "\n",
       "   FACILITIES#GENERAL  FACILITIES#MISCELLANEOUS  FACILITIES#PRICES  \\\n",
       "0                 0.0                       0.0                0.0   \n",
       "1                 0.0                       0.0                0.0   \n",
       "2                 0.0                       0.0                0.0   \n",
       "3                 0.0                       0.0                0.0   \n",
       "4                 1.0                       0.0                0.0   \n",
       "\n",
       "   FACILITIES#QUALITY  FOOD&DRINKS#MISCELLANEOUS  FOOD&DRINKS#PRICES  \\\n",
       "0                 0.0                        0.0                 0.0   \n",
       "1                 0.0                        0.0                 0.0   \n",
       "2                 0.0                        0.0                 0.0   \n",
       "3                 0.0                        0.0                 0.0   \n",
       "4                 0.0                        0.0                 0.0   \n",
       "\n",
       "   FOOD&DRINKS#QUALITY  ...  ROOMS#QUALITY  ROOM_AMENITIES#CLEANLINESS  \\\n",
       "0                  0.0  ...            0.0                         0.0   \n",
       "1                  0.0  ...            0.0                         0.0   \n",
       "2                  0.0  ...            0.0                         0.0   \n",
       "3                  0.0  ...            0.0                         0.0   \n",
       "4                  0.0  ...            0.0                         0.0   \n",
       "\n",
       "   ROOM_AMENITIES#COMFORT  ROOM_AMENITIES#DESIGN&FEATURES  \\\n",
       "0                     0.0                             0.0   \n",
       "1                     0.0                             0.0   \n",
       "2                     0.0                             0.0   \n",
       "3                     0.0                             0.0   \n",
       "4                     0.0                             0.0   \n",
       "\n",
       "   ROOM_AMENITIES#GENERAL  ROOM_AMENITIES#MISCELLANEOUS  \\\n",
       "0                     0.0                           0.0   \n",
       "1                     0.0                           0.0   \n",
       "2                     0.0                           0.0   \n",
       "3                     0.0                           0.0   \n",
       "4                     0.0                           0.0   \n",
       "\n",
       "   ROOM_AMENITIES#PRICES  ROOM_AMENITIES#QUALITY  SERVICE#GENERAL  \\\n",
       "0                    0.0                     0.0              0.0   \n",
       "1                    0.0                     0.0              0.0   \n",
       "2                    0.0                     0.0              1.0   \n",
       "3                    0.0                     0.0              1.0   \n",
       "4                    0.0                     0.0              1.0   \n",
       "\n",
       "                                         aspect_term  \n",
       "0  rộng_rãi khách_sạn vắng dịch_vụ chất_lượng cao...  \n",
       "1  địa_điểm thuận_tiện vòng bán_kính nhiều quán ă...  \n",
       "2                            phục_vụ view đẹp vị_trí  \n",
       "3                 thuận_tiện sạch_sẽ vui_vẻ hài_lòng  \n",
       "4  vị_trí đẹp có quán bar view đẹp nhân_viên thân...  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aspect_train_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3001,), (3001, 34), (2000,), (2000, 34), (600,), (600, 34))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_aspect_train_base = df_aspect_train_base.aspect_term\n",
    "y_aspect_train = df_aspect_train_base.drop(columns=['aspect_term'])\n",
    "\n",
    "x_aspect_val_base = df_aspect_val_base.aspect_term\n",
    "y_aspect_val = df_aspect_val_base.drop(columns=['aspect_term'])\n",
    "\n",
    "x_aspect_test_base = df_aspect_test_base.aspect_term\n",
    "y_aspect_test = df_aspect_test_base.drop(columns=['aspect_term'])\n",
    "\n",
    "x_aspect_train_base.shape, y_aspect_train.shape, x_aspect_val_base.shape, y_aspect_val.shape, x_aspect_test_base.shape, y_aspect_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3001, 5560)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_base = TfidfVectorizer()\n",
    "x_aspect_train_vect = vectorizer_base.fit_transform(x_aspect_train_base)\n",
    "x_aspect_val_vect = vectorizer_base.transform(x_aspect_val_base)\n",
    "x_aspect_test_vect = vectorizer_base.transform(x_aspect_test_base)\n",
    "test_text = vectorizer_base.transform([extract_aspect_terms(text_preprocess(text))])\n",
    "\n",
    "x_aspect_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_base = MultiOutputClassifier(LogisticRegression()).fit(x_aspect_train_vect, y_aspect_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Hamming Loss: 0.06738930160534724\n",
      "Accuracy: 0.157947350883039\n",
      "Precision (Micro): 0.9303174024078803\n",
      "Recall (Micro): 0.5482691894216297\n",
      "F1 Score (Micro): 0.6899350649350648\n",
      "Precision (Macro): 0.6749370864842208\n",
      "Recall (Macro): 0.2508173063350151\n",
      "F1 Score (Macro): 0.3162240548105005\n",
      "\n",
      "\n",
      " validation\n",
      "Hamming Loss: 0.06551470588235295\n",
      "Accuracy: 0.1405\n",
      "Precision (Micro): 0.828875681030213\n",
      "Recall (Micro): 0.4706792293629588\n",
      "F1 Score (Micro): 0.6004125930576734\n",
      "Precision (Macro): 0.4356671256421353\n",
      "Recall (Macro): 0.19348742609514696\n",
      "F1 Score (Macro): 0.23804076933121465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_res = multi_label_metrics(y_aspect_train, clf_base.predict(x_aspect_train_vect))\n",
    "val_res = multi_label_metrics(y_aspect_val, clf_base.predict(x_aspect_val_vect))\n",
    "test_res = multi_label_metrics(y_aspect_test, clf_base.predict(x_aspect_test_vect))\n",
    "\n",
    "print(\"train\")\n",
    "for metric, value in train_res.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n\\n validation\")\n",
    "for metric, value in val_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test\n",
      "Hamming Loss: 0.07916666666666666\n",
      "Accuracy: 0.08\n",
      "Precision (Micro): 0.8419195483415667\n",
      "Recall (Micro): 0.461687306501548\n",
      "F1 Score (Micro): 0.5963509122719319\n",
      "Precision (Macro): 0.4958716621846244\n",
      "Recall (Macro): 0.20046229614435584\n",
      "F1 Score (Macro): 0.2478286742413716\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n test\") \n",
    "for metric, value in test_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCATION#GENERAL\n",
      "ROOMS#CLEANLINESS\n",
      "ROOMS#DESIGN&FEATURES\n",
      "SERVICE#GENERAL\n",
      "\n",
      " ROOMS#DESIGN&FEATURES, ROOMS#CLEANLINESS, LOCATION#GENERAL, SERVICE#GENERAL, ROOMS#GENERAL, ROOM_AMENITIES#DESIGN&FEATURES\n"
     ]
    }
   ],
   "source": [
    "print_column_names(clf_base.predict(test_text)[0], column_names)\n",
    "print(\"\\n\", correct_aspect_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "        FACILITIES#CLEANLINESS       1.00      0.20      0.33         5\n",
      "            FACILITIES#COMFORT       0.00      0.00      0.00        26\n",
      "    FACILITIES#DESIGN&FEATURES       1.00      0.11      0.19        65\n",
      "            FACILITIES#GENERAL       0.00      0.00      0.00        21\n",
      "      FACILITIES#MISCELLANEOUS       0.00      0.00      0.00         8\n",
      "             FACILITIES#PRICES       0.00      0.00      0.00        13\n",
      "            FACILITIES#QUALITY       1.00      0.08      0.15        51\n",
      "     FOOD&DRINKS#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "            FOOD&DRINKS#PRICES       0.00      0.00      0.00         9\n",
      "           FOOD&DRINKS#QUALITY       0.83      0.74      0.78       129\n",
      "     FOOD&DRINKS#STYLE&OPTIONS       0.80      0.59      0.68       124\n",
      "             HOTEL#CLEANLINESS       0.92      0.16      0.28        67\n",
      "                 HOTEL#COMFORT       0.64      0.41      0.50        94\n",
      "         HOTEL#DESIGN&FEATURES       0.64      0.25      0.36        85\n",
      "                 HOTEL#GENERAL       0.87      0.47      0.61       151\n",
      "           HOTEL#MISCELLANEOUS       0.00      0.00      0.00        68\n",
      "                  HOTEL#PRICES       0.76      0.35      0.48        71\n",
      "                 HOTEL#QUALITY       0.00      0.00      0.00        13\n",
      "              LOCATION#GENERAL       0.95      0.81      0.88       221\n",
      "             ROOMS#CLEANLINESS       0.74      0.52      0.61       200\n",
      "                 ROOMS#COMFORT       0.69      0.19      0.30        93\n",
      "         ROOMS#DESIGN&FEATURES       0.74      0.57      0.64       198\n",
      "                 ROOMS#GENERAL       1.00      0.02      0.03        57\n",
      "           ROOMS#MISCELLANEOUS       0.00      0.00      0.00         4\n",
      "                  ROOMS#PRICES       0.60      0.10      0.18        29\n",
      "                 ROOMS#QUALITY       0.00      0.00      0.00        10\n",
      "    ROOM_AMENITIES#CLEANLINESS       0.00      0.00      0.00        46\n",
      "        ROOM_AMENITIES#COMFORT       1.00      0.03      0.06        68\n",
      "ROOM_AMENITIES#DESIGN&FEATURES       0.83      0.13      0.23       144\n",
      "        ROOM_AMENITIES#GENERAL       0.43      0.09      0.15        32\n",
      "  ROOM_AMENITIES#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "         ROOM_AMENITIES#PRICES       0.00      0.00      0.00         1\n",
      "        ROOM_AMENITIES#QUALITY       0.50      0.02      0.03        59\n",
      "               SERVICE#GENERAL       0.94      0.97      0.95       416\n",
      "\n",
      "                     micro avg       0.84      0.46      0.60      2584\n",
      "                     macro avg       0.50      0.20      0.25      2584\n",
      "                  weighted avg       0.75      0.46      0.52      2584\n",
      "                   samples avg       0.81      0.50      0.58      2584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_aspect_test, clf_base.predict(x_aspect_test_vect), target_names=column_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 1: use cleaned text instead of aspect term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aspect_train_test1 = df_aspect_train.drop(columns=['text', 'aspect_term'])\n",
    "df_aspect_val_test1 = df_aspect_val.drop(columns=['text', 'aspect_term'])\n",
    "df_aspect_test_test1 = df_aspect_test.drop(columns=['text', 'aspect_term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3001,), (3001, 34), (2000,), (2000, 34), (600,), (600, 34))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_aspect_train_test1 = df_aspect_train_test1.cleaned_text\n",
    "\n",
    "x_aspect_val_test1 = df_aspect_val_test1.cleaned_text\n",
    "\n",
    "x_aspect_test_test1 = df_aspect_test_test1.cleaned_text\n",
    "\n",
    "x_aspect_train_test1.shape, y_aspect_train.shape, x_aspect_val_test1.shape, y_aspect_val.shape, x_aspect_test_test1.shape, y_aspect_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3001, 5973)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_test1 = TfidfVectorizer()\n",
    "x_aspect_train_vect = vectorizer_test1.fit_transform(x_aspect_train_test1)\n",
    "x_aspect_val_vect = vectorizer_test1.transform(x_aspect_val_test1)\n",
    "x_aspect_test_vect = vectorizer_test1.transform(x_aspect_test_test1)\n",
    "test_text = vectorizer_test1.transform([text_preprocess(text)])\n",
    "\n",
    "x_aspect_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_test1 = MultiOutputClassifier(LogisticRegression()).fit(x_aspect_train_vect, y_aspect_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Hamming Loss: 0.06798714154105494\n",
      "Accuracy: 0.15594801732755748\n",
      "Precision (Micro): 0.9327658524549717\n",
      "Recall (Micro): 0.541890632838816\n",
      "F1 Score (Micro): 0.6855251824652069\n",
      "Precision (Macro): 0.6251547623876699\n",
      "Recall (Macro): 0.24398417650027207\n",
      "F1 Score (Macro): 0.30736867951569463\n",
      "\n",
      "\n",
      " validation\n",
      "Hamming Loss: 0.06576470588235295\n",
      "Accuracy: 0.1415\n",
      "Precision (Micro): 0.8440677966101695\n",
      "Recall (Micro): 0.45521023765996343\n",
      "F1 Score (Micro): 0.5914489311163895\n",
      "Precision (Macro): 0.46312395951087926\n",
      "Recall (Macro): 0.1834275017794106\n",
      "F1 Score (Macro): 0.22916144316875897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_res = multi_label_metrics(y_aspect_train, clf_test1.predict(x_aspect_train_vect))\n",
    "val_res = multi_label_metrics(y_aspect_val, clf_test1.predict(x_aspect_val_vect))\n",
    "test_res = multi_label_metrics(y_aspect_test, clf_test1.predict(x_aspect_test_vect))\n",
    "\n",
    "print(\"train\")\n",
    "for metric, value in train_res.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n\\n validation\")\n",
    "for metric, value in val_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Hamming Loss: 0.07857843137254902\n",
      "Accuracy: 0.08833333333333333\n",
      "Precision (Micro): 0.851109520400859\n",
      "Recall (Micro): 0.4601393188854489\n",
      "F1 Score (Micro): 0.597337352424014\n",
      "Precision (Macro): 0.4958755062499653\n",
      "Recall (Macro): 0.19622292112615086\n",
      "F1 Score (Macro): 0.2435223215680511\n"
     ]
    }
   ],
   "source": [
    "print(\"test\") \n",
    "for metric, value in test_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCATION#GENERAL\n",
      "ROOMS#CLEANLINESS\n",
      "ROOMS#DESIGN&FEATURES\n",
      "SERVICE#GENERAL\n",
      "\n",
      " ROOMS#DESIGN&FEATURES, ROOMS#CLEANLINESS, LOCATION#GENERAL, SERVICE#GENERAL, ROOMS#GENERAL, ROOM_AMENITIES#DESIGN&FEATURES\n"
     ]
    }
   ],
   "source": [
    "print_column_names(clf_test1.predict(test_text)[0], column_names)\n",
    "print(\"\\n\", correct_aspect_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "        FACILITIES#CLEANLINESS       0.00      0.00      0.00         5\n",
      "            FACILITIES#COMFORT       0.00      0.00      0.00        26\n",
      "    FACILITIES#DESIGN&FEATURES       1.00      0.12      0.22        65\n",
      "            FACILITIES#GENERAL       1.00      0.05      0.09        21\n",
      "      FACILITIES#MISCELLANEOUS       0.00      0.00      0.00         8\n",
      "             FACILITIES#PRICES       0.00      0.00      0.00        13\n",
      "            FACILITIES#QUALITY       1.00      0.08      0.15        51\n",
      "     FOOD&DRINKS#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "            FOOD&DRINKS#PRICES       0.00      0.00      0.00         9\n",
      "           FOOD&DRINKS#QUALITY       0.84      0.71      0.77       129\n",
      "     FOOD&DRINKS#STYLE&OPTIONS       0.79      0.56      0.65       124\n",
      "             HOTEL#CLEANLINESS       0.92      0.16      0.28        67\n",
      "                 HOTEL#COMFORT       0.62      0.32      0.42        94\n",
      "         HOTEL#DESIGN&FEATURES       0.82      0.39      0.53        85\n",
      "                 HOTEL#GENERAL       0.87      0.58      0.70       151\n",
      "           HOTEL#MISCELLANEOUS       0.00      0.00      0.00        68\n",
      "                  HOTEL#PRICES       0.78      0.35      0.49        71\n",
      "                 HOTEL#QUALITY       0.00      0.00      0.00        13\n",
      "              LOCATION#GENERAL       0.95      0.78      0.86       221\n",
      "             ROOMS#CLEANLINESS       0.75      0.52      0.61       200\n",
      "                 ROOMS#COMFORT       0.80      0.17      0.28        93\n",
      "         ROOMS#DESIGN&FEATURES       0.75      0.54      0.63       198\n",
      "                 ROOMS#GENERAL       1.00      0.04      0.07        57\n",
      "           ROOMS#MISCELLANEOUS       0.00      0.00      0.00         4\n",
      "                  ROOMS#PRICES       0.60      0.10      0.18        29\n",
      "                 ROOMS#QUALITY       0.00      0.00      0.00        10\n",
      "    ROOM_AMENITIES#CLEANLINESS       0.00      0.00      0.00        46\n",
      "        ROOM_AMENITIES#COMFORT       1.00      0.03      0.06        68\n",
      "ROOM_AMENITIES#DESIGN&FEATURES       0.76      0.13      0.22       144\n",
      "        ROOM_AMENITIES#GENERAL       0.33      0.06      0.11        32\n",
      "  ROOM_AMENITIES#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "         ROOM_AMENITIES#PRICES       0.00      0.00      0.00         1\n",
      "        ROOM_AMENITIES#QUALITY       0.33      0.02      0.03        59\n",
      "               SERVICE#GENERAL       0.93      0.97      0.95       416\n",
      "\n",
      "                     micro avg       0.85      0.46      0.60      2584\n",
      "                     macro avg       0.50      0.20      0.24      2584\n",
      "                  weighted avg       0.76      0.46      0.52      2584\n",
      "                   samples avg       0.81      0.49      0.58      2584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_aspect_test, clf_test1.predict(x_aspect_test_vect), target_names=column_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 2: use phobert instead of tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test2.1: phobert + base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vinai/phobert-base': 256, 'vinai/phobert-large': 256}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "PRETRAINED_MODEL = 'vinai/phobert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode: [0, 218, 8, 649, 212, 956, 2413, 195, 5, 2]\n",
      "Decode: <s> Tôi là sinh_viên trường đại_học Công_nghệ thông_tin. </s>\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode('Tôi là sinh_viên trường đại_học Công_nghệ thông_tin .') # When use PhoBERT\n",
    "print('Encode:', tokens)\n",
    "print('Decode:', tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_aspect_train_vect = tokenizer.batch_encode_plus(x_aspect_train_base, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "x_aspect_val_vect = tokenizer.batch_encode_plus(x_aspect_val_base, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "x_aspect_test_vect = tokenizer.batch_encode_plus(x_aspect_test_base, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "test_text = tokenizer.batch_encode_plus([extract_aspect_terms(text_preprocess(text))], pad_to_max_length=True, max_length=256, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_aspect_train_vect.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf_test21 = MultiOutputClassifier(LogisticRegression()).fit(x_aspect_train_vect['input_ids'], y_aspect_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Hamming Loss: 0.11870552952937256\n",
      "Accuracy: 0.03365544818393869\n",
      "Precision (Micro): 0.6469742934695832\n",
      "Recall (Micro): 0.2904034974557443\n",
      "F1 Score (Micro): 0.4008705975464978\n",
      "Precision (Macro): 0.7023189482599674\n",
      "Recall (Macro): 0.2792163874996363\n",
      "F1 Score (Macro): 0.36663196156257827\n",
      "\n",
      "\n",
      " validation\n",
      "Hamming Loss: 0.10442647058823529\n",
      "Accuracy: 0.028\n",
      "Precision (Micro): 0.5017972681524083\n",
      "Recall (Micro): 0.1963155674307411\n",
      "F1 Score (Micro): 0.28221975133933086\n",
      "Precision (Macro): 0.1778037156766603\n",
      "Recall (Macro): 0.05760101450010319\n",
      "F1 Score (Macro): 0.07150117021487022\n"
     ]
    }
   ],
   "source": [
    "train_res = multi_label_metrics(y_aspect_train, clf_test21.predict(x_aspect_train_vect['input_ids']))\n",
    "val_res = multi_label_metrics(y_aspect_val, clf_test21.predict(x_aspect_val_vect['input_ids']))\n",
    "test_res = multi_label_metrics(y_aspect_test, clf_test21.predict(x_aspect_test_vect['input_ids']))\n",
    "\n",
    "print(\"train\")\n",
    "for metric, value in train_res.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n\\n validation\")\n",
    "for metric, value in val_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Hamming Loss: 0.1271078431372549\n",
      "Accuracy: 0.005\n",
      "Precision (Micro): 0.4957825679475164\n",
      "Recall (Micro): 0.20472136222910217\n",
      "F1 Score (Micro): 0.28978362092577375\n",
      "Precision (Macro): 0.1955801649929933\n",
      "Recall (Macro): 0.0724442084942529\n",
      "F1 Score (Macro): 0.09077881192497139\n"
     ]
    }
   ],
   "source": [
    "print(\"test\") \n",
    "for metric, value in test_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "        FACILITIES#CLEANLINESS       0.00      0.00      0.00         5\n",
      "            FACILITIES#COMFORT       0.11      0.04      0.06        26\n",
      "    FACILITIES#DESIGN&FEATURES       0.34      0.15      0.21        65\n",
      "            FACILITIES#GENERAL       0.00      0.00      0.00        21\n",
      "      FACILITIES#MISCELLANEOUS       0.00      0.00      0.00         8\n",
      "             FACILITIES#PRICES       0.00      0.00      0.00        13\n",
      "            FACILITIES#QUALITY       0.08      0.02      0.03        51\n",
      "     FOOD&DRINKS#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "            FOOD&DRINKS#PRICES       0.29      0.22      0.25         9\n",
      "           FOOD&DRINKS#QUALITY       0.20      0.05      0.08       129\n",
      "     FOOD&DRINKS#STYLE&OPTIONS       0.36      0.08      0.13       124\n",
      "             HOTEL#CLEANLINESS       0.00      0.00      0.00        67\n",
      "                 HOTEL#COMFORT       0.16      0.10      0.12        94\n",
      "         HOTEL#DESIGN&FEATURES       0.34      0.13      0.19        85\n",
      "                 HOTEL#GENERAL       0.39      0.19      0.26       151\n",
      "           HOTEL#MISCELLANEOUS       0.14      0.01      0.03        68\n",
      "                  HOTEL#PRICES       0.14      0.01      0.03        71\n",
      "                 HOTEL#QUALITY       0.00      0.00      0.00        13\n",
      "              LOCATION#GENERAL       0.59      0.19      0.29       221\n",
      "             ROOMS#CLEANLINESS       0.53      0.04      0.07       200\n",
      "                 ROOMS#COMFORT       0.30      0.03      0.06        93\n",
      "         ROOMS#DESIGN&FEATURES       0.36      0.05      0.09       198\n",
      "                 ROOMS#GENERAL       0.14      0.02      0.03        57\n",
      "           ROOMS#MISCELLANEOUS       0.00      0.00      0.00         4\n",
      "                  ROOMS#PRICES       0.33      0.10      0.16        29\n",
      "                 ROOMS#QUALITY       0.00      0.00      0.00        10\n",
      "    ROOM_AMENITIES#CLEANLINESS       0.00      0.00      0.00        46\n",
      "        ROOM_AMENITIES#COMFORT       0.00      0.00      0.00        68\n",
      "ROOM_AMENITIES#DESIGN&FEATURES       0.64      0.05      0.09       144\n",
      "        ROOM_AMENITIES#GENERAL       0.40      0.06      0.11        32\n",
      "  ROOM_AMENITIES#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "         ROOM_AMENITIES#PRICES       0.00      0.00      0.00         1\n",
      "        ROOM_AMENITIES#QUALITY       0.11      0.02      0.03        59\n",
      "               SERVICE#GENERAL       0.70      0.89      0.78       416\n",
      "\n",
      "                     micro avg       0.50      0.20      0.29      2584\n",
      "                     macro avg       0.20      0.07      0.09      2584\n",
      "                  weighted avg       0.38      0.20      0.22      2584\n",
      "                   samples avg       0.55      0.20      0.27      2584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_aspect_test, clf_test21.predict(x_aspect_test_vect['input_ids']), \n",
    "                            target_names=column_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE#GENERAL\n",
      "\n",
      " ROOMS#DESIGN&FEATURES, ROOMS#CLEANLINESS, LOCATION#GENERAL, SERVICE#GENERAL, ROOMS#GENERAL, ROOM_AMENITIES#DESIGN&FEATURES\n"
     ]
    }
   ],
   "source": [
    "print_column_names(clf_test21.predict(test_text['input_ids'])[0], column_names)\n",
    "print(\"\\n\", correct_aspect_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 2.2: phobert + test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_aspect_train_vect = tokenizer.batch_encode_plus(x_aspect_train_test1, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "x_aspect_val_vect = tokenizer.batch_encode_plus(x_aspect_val_test1, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "x_aspect_test_vect = tokenizer.batch_encode_plus(x_aspect_test_test1, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "test_text = tokenizer.batch_encode_plus(text_preprocess(text), pad_to_max_length=True, max_length=256, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf_test22 = MultiOutputClassifier(LogisticRegression()).fit(x_aspect_train_vect['input_ids'], y_aspect_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Hamming Loss: 0.11596134621792736\n",
      "Accuracy: 0.052649116961012994\n",
      "Precision (Micro): 0.6552026928142837\n",
      "Recall (Micro): 0.320862896868057\n",
      "F1 Score (Micro): 0.4307707110555181\n",
      "Precision (Macro): 0.7177762116591748\n",
      "Recall (Macro): 0.34037816168390345\n",
      "F1 Score (Macro): 0.4267571083534116\n",
      "\n",
      "\n",
      " validation\n",
      "Hamming Loss: 0.10764705882352942\n",
      "Accuracy: 0.024\n",
      "Precision (Micro): 0.46485031954254963\n",
      "Recall (Micro): 0.1943467866685417\n",
      "F1 Score (Micro): 0.27409758032526776\n",
      "Precision (Macro): 0.17041034418872786\n",
      "Recall (Macro): 0.060102436833532426\n",
      "F1 Score (Macro): 0.07640368214177706\n"
     ]
    }
   ],
   "source": [
    "train_res = multi_label_metrics(y_aspect_train, clf_test22.predict(x_aspect_train_vect['input_ids']))\n",
    "val_res = multi_label_metrics(y_aspect_val, clf_test22.predict(x_aspect_val_vect['input_ids']))\n",
    "test_res = multi_label_metrics(y_aspect_test, clf_test22.predict(x_aspect_test_vect['input_ids']))\n",
    "\n",
    "\n",
    "print(\"train\")\n",
    "for metric, value in train_res.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n\\n validation\")\n",
    "for metric, value in val_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Hamming Loss: 0.13357843137254902\n",
      "Accuracy: 0.005\n",
      "Precision (Micro): 0.4354986276303751\n",
      "Recall (Micro): 0.18421052631578946\n",
      "F1 Score (Micro): 0.2589067174326897\n",
      "Precision (Macro): 0.16426088760140697\n",
      "Recall (Macro): 0.06199958692763727\n",
      "F1 Score (Macro): 0.0773191976277992\n"
     ]
    }
   ],
   "source": [
    "print(\"test\") \n",
    "for metric, value in test_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "        FACILITIES#CLEANLINESS       0.00      0.00      0.00         5\n",
      "            FACILITIES#COMFORT       0.12      0.04      0.06        26\n",
      "    FACILITIES#DESIGN&FEATURES       0.24      0.09      0.13        65\n",
      "            FACILITIES#GENERAL       0.00      0.00      0.00        21\n",
      "      FACILITIES#MISCELLANEOUS       0.00      0.00      0.00         8\n",
      "             FACILITIES#PRICES       0.11      0.08      0.09        13\n",
      "            FACILITIES#QUALITY       0.12      0.02      0.03        51\n",
      "     FOOD&DRINKS#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "            FOOD&DRINKS#PRICES       0.11      0.11      0.11         9\n",
      "           FOOD&DRINKS#QUALITY       0.19      0.03      0.05       129\n",
      "     FOOD&DRINKS#STYLE&OPTIONS       0.22      0.04      0.07       124\n",
      "             HOTEL#CLEANLINESS       0.00      0.00      0.00        67\n",
      "                 HOTEL#COMFORT       0.11      0.09      0.10        94\n",
      "         HOTEL#DESIGN&FEATURES       0.20      0.09      0.13        85\n",
      "                 HOTEL#GENERAL       0.32      0.19      0.24       151\n",
      "           HOTEL#MISCELLANEOUS       0.20      0.03      0.05        68\n",
      "                  HOTEL#PRICES       0.21      0.04      0.07        71\n",
      "                 HOTEL#QUALITY       0.00      0.00      0.00        13\n",
      "              LOCATION#GENERAL       0.52      0.17      0.25       221\n",
      "             ROOMS#CLEANLINESS       0.62      0.05      0.09       200\n",
      "                 ROOMS#COMFORT       0.08      0.01      0.02        93\n",
      "         ROOMS#DESIGN&FEATURES       0.51      0.10      0.16       198\n",
      "                 ROOMS#GENERAL       0.17      0.02      0.03        57\n",
      "           ROOMS#MISCELLANEOUS       0.00      0.00      0.00         4\n",
      "                  ROOMS#PRICES       0.08      0.03      0.05        29\n",
      "                 ROOMS#QUALITY       0.00      0.00      0.00        10\n",
      "    ROOM_AMENITIES#CLEANLINESS       0.11      0.02      0.04        46\n",
      "        ROOM_AMENITIES#COMFORT       0.22      0.03      0.05        68\n",
      "ROOM_AMENITIES#DESIGN&FEATURES       0.42      0.03      0.06       144\n",
      "        ROOM_AMENITIES#GENERAL       0.00      0.00      0.00        32\n",
      "  ROOM_AMENITIES#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "         ROOM_AMENITIES#PRICES       0.00      0.00      0.00         1\n",
      "        ROOM_AMENITIES#QUALITY       0.00      0.00      0.00        59\n",
      "               SERVICE#GENERAL       0.69      0.79      0.74       416\n",
      "\n",
      "                     micro avg       0.44      0.18      0.26      2584\n",
      "                     macro avg       0.16      0.06      0.08      2584\n",
      "                  weighted avg       0.35      0.18      0.20      2584\n",
      "                   samples avg       0.47      0.18      0.24      2584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_aspect_test, clf_test22.predict(x_aspect_test_vect['input_ids']), \n",
    "                            target_names=column_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE#GENERAL\n",
      "\n",
      " ROOMS#DESIGN&FEATURES, ROOMS#CLEANLINESS, LOCATION#GENERAL, SERVICE#GENERAL, ROOMS#GENERAL, ROOM_AMENITIES#DESIGN&FEATURES\n"
     ]
    }
   ],
   "source": [
    "print_column_names(clf_test21.predict(test_text['input_ids'])[0], column_names)\n",
    "print(\"\\n\", correct_aspect_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aspect category polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13954,), (7111,), (2584,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df_train.cleaned_text + ' ' + df_train.aspect_cat\n",
    "x_val  = df_val.cleaned_text + ' ' + df_val.aspect_cat\n",
    "x_test = df_test.cleaned_text + ' ' + df_test.aspect_cat\n",
    "\n",
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13954, 5987), (7111, 5987), (2584, 5987))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x_train_vect = vectorizer.fit_transform(x_train)\n",
    "x_val_vect = vectorizer.transform(x_val)\n",
    "x_test_vect = vectorizer.transform(x_test)\n",
    "\n",
    "x_train_vect.shape, x_val_vect.shape, x_test_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.fit_transform(df_train.polarity)\n",
    "y_val = le.transform(df_val.polarity)\n",
    "y_test = le.transform(df_test.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = multi_label_metrics(y_train, model.predict(x_train_vect))\n",
    "val_res = multi_label_metrics(y_val, model.predict(x_val_vect))\n",
    "test_res = multi_label_metrics(y_test, model.predict(x_test_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Hamming Loss: 0.1411781568009173\n",
      "Accuracy: 0.8588218431990827\n",
      "Precision (Micro): 0.8588218431990827\n",
      "Recall (Micro): 0.8588218431990827\n",
      "F1 Score (Micro): 0.8588218431990827\n",
      "Precision (Macro): 0.7886508131095876\n",
      "Recall (Macro): 0.5635789518731895\n",
      "F1 Score (Macro): 0.5783081099259779\n",
      "\n",
      "\n",
      " validation\n",
      "Hamming Loss: 0.19969062016594008\n",
      "Accuracy: 0.8003093798340599\n",
      "Precision (Micro): 0.8003093798340599\n",
      "Recall (Micro): 0.8003093798340599\n",
      "F1 Score (Micro): 0.8003093798340599\n",
      "Precision (Macro): 0.6693081426517143\n",
      "Recall (Macro): 0.5057093111219956\n",
      "F1 Score (Macro): 0.5112747761585582\n"
     ]
    }
   ],
   "source": [
    "print(\"train\")\n",
    "for metric, value in train_res.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n\\n validation\")\n",
    "for metric, value in val_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test\n",
      "Hamming Loss: 0.21130030959752322\n",
      "Accuracy: 0.7886996904024768\n",
      "Precision (Micro): 0.7886996904024768\n",
      "Recall (Micro): 0.7886996904024768\n",
      "F1 Score (Micro): 0.7886996904024768\n",
      "Precision (Macro): 0.8291635019163109\n",
      "Recall (Macro): 0.5170095782090885\n",
      "F1 Score (Macro): 0.5132607392780288\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n test\") \n",
    "for metric, value in test_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.64      0.65       645\n",
      "     neutral       1.00      0.02      0.03       133\n",
      "    positive       0.83      0.90      0.86      1806\n",
      "\n",
      "    accuracy                           0.79      2584\n",
      "   macro avg       0.83      0.52      0.51      2584\n",
      "weighted avg       0.80      0.79      0.77      2584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(x_test_vect), target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_category(binary_list, column_names):\n",
    "    aspect_category = []\n",
    "    for i, value in enumerate(binary_list):\n",
    "        if value == 1:\n",
    "            aspect_category.append(column_names[i])\n",
    "    return aspect_category\n",
    "\n",
    "def print_res(text, cat_sen):\n",
    "    print(text)\n",
    "    for cat, sen in cat_sen.items():\n",
    "        print(f\"{{{cat}, {sen}}}\", end=' ')\n",
    "\n",
    "def absa_test1(text, acd, acd_vectorizer, model, model_vectorizer):\n",
    "    cleaned_text = text_preprocess(text)\n",
    "    cat_sen = {}\n",
    "    acd_vector = acd_vectorizer.transform([cleaned_text])\n",
    "    aspect_cand = get_aspect_category(acd.predict(acd_vector)[0], column_names)\n",
    "    for aspect in aspect_cand:\n",
    "        sentiment = le.inverse_transform(model.predict(model_vectorizer.transform([cleaned_text + ' ' + aspect])))[0]\n",
    "        cat_sen[aspect] = sentiment\n",
    "        \n",
    "    print_res(text, cat_sen)\n",
    "    \n",
    "def absa_base(text, acd, acd_vectorizer, model, model_vectorizer):\n",
    "    cleaned_text = text_preprocess(text)\n",
    "    aspect_text = extract_aspect_terms(cleaned_text)\n",
    "    cat_sen = {}\n",
    "    acd_vector = acd_vectorizer.transform([aspect_text])\n",
    "    aspect_cand = get_aspect_category(acd.predict(acd_vector)[0], column_names)\n",
    "    for aspect in aspect_cand:\n",
    "        sentiment = le.inverse_transform(model.predict(model_vectorizer.transform([cleaned_text + ' ' + aspect])))[0]\n",
    "        cat_sen[aspect] = sentiment\n",
    "        \n",
    "    print_res(text, cat_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rộng rãi, sạch sẽ. Có chỗ trong phòng không bắt được wifi\n",
      "{FACILITIES#QUALITY, negative} {ROOMS#CLEANLINESS, positive} {ROOMS#DESIGN&FEATURES, positive} "
     ]
    }
   ],
   "source": [
    "usr_rev = \"Rộng rãi, sạch sẽ. Có chỗ trong phòng không bắt được wifi\"\n",
    "\n",
    "absa_test1(usr_rev, clf_test1, vectorizer_test1, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rộng rãi, sạch sẽ. Có chỗ trong phòng không bắt được wifi\n",
      "{FACILITIES#QUALITY, negative} {ROOMS#CLEANLINESS, positive} {ROOMS#DESIGN&FEATURES, positive} "
     ]
    }
   ],
   "source": [
    "usr_rev = \"Rộng rãi, sạch sẽ. Có chỗ trong phòng không bắt được wifi\"\n",
    "\n",
    "absa_base(usr_rev, clf_base, vectorizer_base, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rộng_rãi sạch_sẽ có chỗ trong phòng không bắt được wifi'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocess(usr_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rộng_rãi sạch_sẽ có chỗ phòng bắt wifi'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_aspect_terms(text_preprocess(usr_rev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
