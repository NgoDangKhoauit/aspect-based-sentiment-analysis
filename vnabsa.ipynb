{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 16:08:36.504737: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-23 16:08:36.901269: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-23 16:08:37.583288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"./VLSP2018-SA-train-dev-test/1-VLSP2018-SA-Hotel-train (7-3-2018).txt\",\n",
    "    \"./VLSP2018-SA-train-dev-test/2-VLSP2018-SA-Hotel-dev (7-3-2018).txt\",\n",
    "    \"./VLSP2018-SA-train-dev-test/3-VLSP2018-SA-Hotel-test (8-3-2018).txt\"\n",
    "]\n",
    "\n",
    "file_types = ['train', 'dev', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        line_number = 1\n",
    "        data_list = []\n",
    "\n",
    "        text = None\n",
    "        aspects = []\n",
    "        polarities = []\n",
    "\n",
    "        for line in tqdm(file):\n",
    "            if line == '\\n':\n",
    "                if text and aspects:\n",
    "                    for aspect, polarity in zip(aspects, polarities):\n",
    "                        data_list.append({'text': text, 'aspect_cat': aspect, 'polarity': polarity})\n",
    "                text = None\n",
    "                aspects = []\n",
    "                polarities = []\n",
    "                line_number = 1\n",
    "                continue\n",
    "\n",
    "            if line_number % 2 == 0:\n",
    "                text = line.strip()\n",
    "\n",
    "            if line_number % 3 == 0:\n",
    "                cat_sen = re.findall(r'{(.*?), (.*?)}', line)\n",
    "                for cat, sen in cat_sen:\n",
    "                    aspects.append(cat.strip())\n",
    "                    polarity = sen.strip()\n",
    "                    polarities.append(polarity)\n",
    "\n",
    "            line_number += 1\n",
    "        \n",
    "        # squeeze out the last data\n",
    "        if text and aspects:\n",
    "            for aspect, polarity in zip(aspects, polarities):\n",
    "                data_list.append({'text': text, 'aspect_cat': aspect, 'polarity': polarity})\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(data_list)\n",
    "        df.fillna(0, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "'FACILITIES#CLEANLINESS',\n",
    " 'FACILITIES#COMFORT',\n",
    " 'FACILITIES#DESIGN&FEATURES',\n",
    " 'FACILITIES#GENERAL',\n",
    " 'FACILITIES#MISCELLANEOUS',\n",
    " 'FACILITIES#PRICES',\n",
    " 'FACILITIES#QUALITY',\n",
    " 'FOOD&DRINKS#MISCELLANEOUS',\n",
    " 'FOOD&DRINKS#PRICES',\n",
    " 'FOOD&DRINKS#QUALITY',\n",
    " 'FOOD&DRINKS#STYLE&OPTIONS',\n",
    " 'HOTEL#CLEANLINESS',\n",
    " 'HOTEL#COMFORT',\n",
    " 'HOTEL#DESIGN&FEATURES',\n",
    " 'HOTEL#GENERAL',\n",
    " 'HOTEL#MISCELLANEOUS',\n",
    " 'HOTEL#PRICES',\n",
    " 'HOTEL#QUALITY',\n",
    " 'LOCATION#GENERAL',\n",
    " 'ROOMS#CLEANLINESS',\n",
    " 'ROOMS#COMFORT',\n",
    " 'ROOMS#DESIGN&FEATURES',\n",
    " 'ROOMS#GENERAL',\n",
    " 'ROOMS#MISCELLANEOUS',\n",
    " 'ROOMS#PRICES',\n",
    " 'ROOMS#QUALITY',\n",
    " 'ROOM_AMENITIES#CLEANLINESS',\n",
    " 'ROOM_AMENITIES#COMFORT',\n",
    " 'ROOM_AMENITIES#DESIGN&FEATURES',\n",
    " 'ROOM_AMENITIES#GENERAL',\n",
    " 'ROOM_AMENITIES#MISCELLANEOUS',\n",
    " 'ROOM_AMENITIES#PRICES',\n",
    " 'ROOM_AMENITIES#QUALITY',\n",
    " 'SERVICE#GENERAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{FACILITIES#CLEANLINESS, positive} {FACILITIES#COMFORT, positive} {FACILITIES#DESIGN&FEATURES, positive} {FACILITIES#GENERAL, positive} {FACILITIES#MISCELLANEOUS, positive} {FACILITIES#PRICES, positive} {FACILITIES#QUALITY, positive} {FOOD&DRINKS#MISCELLANEOUS, positive} {FOOD&DRINKS#PRICES, positive} {FOOD&DRINKS#QUALITY, positive} {FOOD&DRINKS#STYLE&OPTIONS, positive} {HOTEL#CLEANLINESS, positive} {HOTEL#COMFORT, positive} {HOTEL#DESIGN&FEATURES, positive} {HOTEL#GENERAL, positive} {HOTEL#MISCELLANEOUS, positive} {HOTEL#PRICES, positive} {HOTEL#QUALITY, positive} {LOCATION#GENERAL, positive} {ROOMS#CLEANLINESS, positive} {ROOMS#COMFORT, positive} {ROOMS#DESIGN&FEATURES, positive} {ROOMS#GENERAL, positive} {ROOMS#MISCELLANEOUS, positive} {ROOMS#PRICES, positive} {ROOMS#QUALITY, positive} {ROOM_AMENITIES#CLEANLINESS, positive} {ROOM_AMENITIES#COMFORT, positive} {ROOM_AMENITIES#DESIGN&FEATURES, positive} {ROOM_AMENITIES#GENERAL, positive} {ROOM_AMENITIES#MISCELLANEOUS, positive} {ROOM_AMENITIES#PRICES, positive} {ROOM_AMENITIES#QUALITY, positive} {SERVICE#GENERAL, positive} "
     ]
    }
   ],
   "source": [
    "for value in column_names:\n",
    "    print(\"{{{value}, positive}}\".format(value=value), end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FACILITIES#CLEANLINESS': 0.0,\n",
       " 'FACILITIES#COMFORT': 0.0,\n",
       " 'FACILITIES#DESIGN&FEATURES': 0.0,\n",
       " 'FACILITIES#GENERAL': 0.0,\n",
       " 'FACILITIES#MISCELLANEOUS': 0.0,\n",
       " 'FACILITIES#PRICES': 0.0,\n",
       " 'FACILITIES#QUALITY': 0.0,\n",
       " 'FOOD&DRINKS#MISCELLANEOUS': 0.0,\n",
       " 'FOOD&DRINKS#PRICES': 0.0,\n",
       " 'FOOD&DRINKS#QUALITY': 0.0,\n",
       " 'FOOD&DRINKS#STYLE&OPTIONS': 0.0,\n",
       " 'HOTEL#CLEANLINESS': 0.0,\n",
       " 'HOTEL#COMFORT': 0.0,\n",
       " 'HOTEL#DESIGN&FEATURES': 0.0,\n",
       " 'HOTEL#GENERAL': 0.0,\n",
       " 'HOTEL#MISCELLANEOUS': 0.0,\n",
       " 'HOTEL#PRICES': 0.0,\n",
       " 'HOTEL#QUALITY': 0.0,\n",
       " 'LOCATION#GENERAL': 0.0,\n",
       " 'ROOMS#CLEANLINESS': 0.0,\n",
       " 'ROOMS#COMFORT': 0.0,\n",
       " 'ROOMS#DESIGN&FEATURES': 0.0,\n",
       " 'ROOMS#GENERAL': 0.0,\n",
       " 'ROOMS#MISCELLANEOUS': 0.0,\n",
       " 'ROOMS#PRICES': 0.0,\n",
       " 'ROOMS#QUALITY': 0.0,\n",
       " 'ROOM_AMENITIES#CLEANLINESS': 0.0,\n",
       " 'ROOM_AMENITIES#COMFORT': 0.0,\n",
       " 'ROOM_AMENITIES#DESIGN&FEATURES': 0.0,\n",
       " 'ROOM_AMENITIES#GENERAL': 0.0,\n",
       " 'ROOM_AMENITIES#MISCELLANEOUS': 0.0,\n",
       " 'ROOM_AMENITIES#PRICES': 0.0,\n",
       " 'ROOM_AMENITIES#QUALITY': 0.0,\n",
       " 'SERVICE#GENERAL': 0.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dict = {column: 0.0 for column in column_names}\n",
    "column_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aspect_data(file_path):\n",
    "    from collections import OrderedDict\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = None\n",
    "        # copy dict\n",
    "        dup = dict(column_dict)\n",
    "        flag = True\n",
    "        data_list = []\n",
    "        for line in tqdm(file):\n",
    "\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            elif line.startswith('{'):\n",
    "                cat_sen = re.findall(r'{(.*?), (.*?)}', line)\n",
    "                for cat, sen in cat_sen:\n",
    "                    if sen.strip() == \"negative\":\n",
    "                        dup[cat] = 1.0\n",
    "                    elif sen.strip() == \"neutral\":\n",
    "                        dup[cat] = 1.0\n",
    "                    elif sen.strip() == \"positive\":\n",
    "                        dup[cat] = 1.0\n",
    "                    else:\n",
    "                        dup[cat] = 0\n",
    "                flag = False\n",
    "            else:\n",
    "                text = line\n",
    "            \n",
    "            if text is not None and not flag:\n",
    "                tmp_dict = OrderedDict([('text', text)] + list(dup.items()))\n",
    "                data_list.append(tmp_dict)\n",
    "                dup = dict(column_dict)\n",
    "                tmp_dict = None\n",
    "                text = None \n",
    "                flag = True\n",
    "                \n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12003it [00:00, 763138.26it/s]\n",
      "7999it [00:00, 1123697.55it/s]\n",
      "2399it [00:00, 956294.93it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"sentiment_data\"):\n",
    "    os.mkdir(\"sentiment_data\")\n",
    "for idx, file_path in enumerate(file_paths):\n",
    "    df = create_sentiment_data(file_path)\n",
    "    df.to_csv('./sentiment_data/{}_hotel_reviews.csv'.format(file_types[idx]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12003it [00:00, 530184.83it/s]\n",
      "7999it [00:00, 609505.64it/s]\n",
      "2399it [00:00, 567520.32it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"aspect_data\"):\n",
    "    os.mkdir(\"aspect_data\")\n",
    "for idx, file_path in enumerate(file_paths):\n",
    "    df = create_aspect_data(file_path)\n",
    "    df.to_csv('./aspect_data/{}_hotel_reviews.csv'.format(file_types[idx]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 09:54:00.021814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:54:00.022535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 09:54:00.022610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_cat</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13949</th>\n",
       "      <td>B·ªØa s√°ng kh√¥ng thay ƒë·ªïi, kh√¥ng c√≥ TV, kh√¥ng d·ªç...</td>\n",
       "      <td>FOOD&amp;DRINKS#STYLE&amp;OPTIONS</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13950</th>\n",
       "      <td>B·ªØa s√°ng kh√¥ng thay ƒë·ªïi, kh√¥ng c√≥ TV, kh√¥ng d·ªç...</td>\n",
       "      <td>ROOM_AMENITIES#DESIGN&amp;FEATURES</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13951</th>\n",
       "      <td>B·ªØa s√°ng kh√¥ng thay ƒë·ªïi, kh√¥ng c√≥ TV, kh√¥ng d·ªç...</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13952</th>\n",
       "      <td>B·ªØa s√°ng kh√¥ng thay ƒë·ªïi, kh√¥ng c√≥ TV, kh√¥ng d·ªç...</td>\n",
       "      <td>ROOMS#CLEANLINESS</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13953</th>\n",
       "      <td>B·ªØa s√°ng kh√¥ng thay ƒë·ªïi, kh√¥ng c√≥ TV, kh√¥ng d·ªç...</td>\n",
       "      <td>ROOM_AMENITIES#PRICES</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "13949  B·ªØa s√°ng kh√¥ng thay ƒë·ªïi, kh√¥ng c√≥ TV, kh√¥ng d·ªç...   \n",
       "13950  B·ªØa s√°ng kh√¥ng thay ƒë·ªïi, kh√¥ng c√≥ TV, kh√¥ng d·ªç...   \n",
       "13951  B·ªØa s√°ng kh√¥ng thay ƒë·ªïi, kh√¥ng c√≥ TV, kh√¥ng d·ªç...   \n",
       "13952  B·ªØa s√°ng kh√¥ng thay ƒë·ªïi, kh√¥ng c√≥ TV, kh√¥ng d·ªç...   \n",
       "13953  B·ªØa s√°ng kh√¥ng thay ƒë·ªïi, kh√¥ng c√≥ TV, kh√¥ng d·ªç...   \n",
       "\n",
       "                           aspect_cat  polarity  \n",
       "13949       FOOD&DRINKS#STYLE&OPTIONS  negative  \n",
       "13950  ROOM_AMENITIES#DESIGN&FEATURES  negative  \n",
       "13951                 SERVICE#GENERAL  negative  \n",
       "13952               ROOMS#CLEANLINESS  negative  \n",
       "13953           ROOM_AMENITIES#PRICES  negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./sentiment_data/train_hotel_reviews.csv')\n",
    "df_val = pd.read_csv('./sentiment_data/dev_hotel_reviews.csv')\n",
    "df_test = pd.read_csv('./sentiment_data/test_hotel_reviews.csv')\n",
    "\n",
    "df_aspect_train = pd.read_csv('./aspect_data/train_hotel_reviews.csv')\n",
    "df_aspect_val = pd.read_csv('./aspect_data/dev_hotel_reviews.csv')\n",
    "df_aspect_test = pd.read_csv('./aspect_data/test_hotel_reviews.csv')\n",
    "\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>FACILITIES#CLEANLINESS</th>\n",
       "      <th>FACILITIES#COMFORT</th>\n",
       "      <th>FACILITIES#DESIGN&amp;FEATURES</th>\n",
       "      <th>FACILITIES#GENERAL</th>\n",
       "      <th>FACILITIES#MISCELLANEOUS</th>\n",
       "      <th>FACILITIES#PRICES</th>\n",
       "      <th>FACILITIES#QUALITY</th>\n",
       "      <th>FOOD&amp;DRINKS#MISCELLANEOUS</th>\n",
       "      <th>FOOD&amp;DRINKS#PRICES</th>\n",
       "      <th>...</th>\n",
       "      <th>ROOMS#PRICES</th>\n",
       "      <th>ROOMS#QUALITY</th>\n",
       "      <th>ROOM_AMENITIES#CLEANLINESS</th>\n",
       "      <th>ROOM_AMENITIES#COMFORT</th>\n",
       "      <th>ROOM_AMENITIES#DESIGN&amp;FEATURES</th>\n",
       "      <th>ROOM_AMENITIES#GENERAL</th>\n",
       "      <th>ROOM_AMENITIES#MISCELLANEOUS</th>\n",
       "      <th>ROOM_AMENITIES#PRICES</th>\n",
       "      <th>ROOM_AMENITIES#QUALITY</th>\n",
       "      <th>SERVICE#GENERAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R·ªông r√£i KS m·ªõi nh∆∞ng r·∫•t v·∫Øng. C√°c d·ªãch v·ª• ch...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ƒê·ªãa ƒëi·ªÉm thu·∫≠n ti·ªán, trong v√≤ng b√°n k√≠nh 1,5km...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ph·ª•c v·ª•, view ƒë·∫πp, v·ªã tr√≠</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thu·∫≠n ti·ªán , s·∫°ch s·∫Ω , vui v·∫ª h√†i l√≤ng</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V·ªã tr√≠ ƒë·∫πp; C√≥ qu√°n bar view ƒë·∫πp; Nh√¢n vi√™n th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  FACILITIES#CLEANLINESS  \\\n",
       "0  R·ªông r√£i KS m·ªõi nh∆∞ng r·∫•t v·∫Øng. C√°c d·ªãch v·ª• ch...                     0.0   \n",
       "1  ƒê·ªãa ƒëi·ªÉm thu·∫≠n ti·ªán, trong v√≤ng b√°n k√≠nh 1,5km...                     0.0   \n",
       "2                          Ph·ª•c v·ª•, view ƒë·∫πp, v·ªã tr√≠                     0.0   \n",
       "3             thu·∫≠n ti·ªán , s·∫°ch s·∫Ω , vui v·∫ª h√†i l√≤ng                     0.0   \n",
       "4  V·ªã tr√≠ ƒë·∫πp; C√≥ qu√°n bar view ƒë·∫πp; Nh√¢n vi√™n th...                     0.0   \n",
       "\n",
       "   FACILITIES#COMFORT  FACILITIES#DESIGN&FEATURES  FACILITIES#GENERAL  \\\n",
       "0                 0.0                         0.0                 0.0   \n",
       "1                 0.0                         0.0                 0.0   \n",
       "2                 0.0                         0.0                 0.0   \n",
       "3                 0.0                         0.0                 0.0   \n",
       "4                 0.0                         0.0                 1.0   \n",
       "\n",
       "   FACILITIES#MISCELLANEOUS  FACILITIES#PRICES  FACILITIES#QUALITY  \\\n",
       "0                       0.0                0.0                 0.0   \n",
       "1                       0.0                0.0                 0.0   \n",
       "2                       0.0                0.0                 0.0   \n",
       "3                       0.0                0.0                 0.0   \n",
       "4                       0.0                0.0                 0.0   \n",
       "\n",
       "   FOOD&DRINKS#MISCELLANEOUS  FOOD&DRINKS#PRICES  ...  ROOMS#PRICES  \\\n",
       "0                        0.0                 0.0  ...           0.0   \n",
       "1                        0.0                 0.0  ...           0.0   \n",
       "2                        0.0                 0.0  ...           0.0   \n",
       "3                        0.0                 0.0  ...           0.0   \n",
       "4                        0.0                 0.0  ...           0.0   \n",
       "\n",
       "   ROOMS#QUALITY  ROOM_AMENITIES#CLEANLINESS  ROOM_AMENITIES#COMFORT  \\\n",
       "0            0.0                         0.0                     0.0   \n",
       "1            0.0                         0.0                     0.0   \n",
       "2            0.0                         0.0                     0.0   \n",
       "3            0.0                         0.0                     0.0   \n",
       "4            0.0                         0.0                     0.0   \n",
       "\n",
       "   ROOM_AMENITIES#DESIGN&FEATURES  ROOM_AMENITIES#GENERAL  \\\n",
       "0                             0.0                     0.0   \n",
       "1                             0.0                     0.0   \n",
       "2                             0.0                     0.0   \n",
       "3                             0.0                     0.0   \n",
       "4                             0.0                     0.0   \n",
       "\n",
       "   ROOM_AMENITIES#MISCELLANEOUS  ROOM_AMENITIES#PRICES  \\\n",
       "0                           0.0                    0.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    0.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   ROOM_AMENITIES#QUALITY  SERVICE#GENERAL  \n",
       "0                     0.0              0.0  \n",
       "1                     0.0              0.0  \n",
       "2                     0.0              1.0  \n",
       "3                     0.0              1.0  \n",
       "4                     0.0              1.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aspect_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_cat</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13954</td>\n",
       "      <td>13954</td>\n",
       "      <td>13954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2949</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Gia ƒë√¨nh t√¥i r·∫•t h√†i l√≤ng khi ·ªü t·∫°i kh√°ch s·∫°n....</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>44</td>\n",
       "      <td>1913</td>\n",
       "      <td>10229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       aspect_cat  \\\n",
       "count                                               13954            13954   \n",
       "unique                                               2949               34   \n",
       "top     Gia ƒë√¨nh t√¥i r·∫•t h√†i l√≤ng khi ·ªü t·∫°i kh√°ch s·∫°n....  SERVICE#GENERAL   \n",
       "freq                                                   44             1913   \n",
       "\n",
       "        polarity  \n",
       "count      13954  \n",
       "unique         3  \n",
       "top     positive  \n",
       "freq       10229  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2949, 34, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.text.nunique(), df_train.aspect_cat.nunique(), df_train.polarity.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aspect_cat\n",
       "SERVICE#GENERAL                   1913\n",
       "HOTEL#GENERAL                     1282\n",
       "LOCATION#GENERAL                  1196\n",
       "HOTEL#COMFORT                     1139\n",
       "ROOMS#DESIGN&FEATURES              916\n",
       "HOTEL#DESIGN&FEATURES              877\n",
       "FOOD&DRINKS#QUALITY                672\n",
       "ROOMS#CLEANLINESS                  659\n",
       "FOOD&DRINKS#STYLE&OPTIONS          570\n",
       "FACILITIES#DESIGN&FEATURES         525\n",
       "HOTEL#PRICES                       496\n",
       "ROOMS#COMFORT                      434\n",
       "ROOM_AMENITIES#DESIGN&FEATURES     355\n",
       "HOTEL#CLEANLINESS                  348\n",
       "ROOMS#GENERAL                      256\n",
       "HOTEL#QUALITY                      246\n",
       "ROOM_AMENITIES#QUALITY             239\n",
       "FACILITIES#GENERAL                 219\n",
       "ROOM_AMENITIES#GENERAL             216\n",
       "FACILITIES#QUALITY                 208\n",
       "ROOMS#PRICES                       196\n",
       "FACILITIES#CLEANLINESS             172\n",
       "ROOMS#QUALITY                      164\n",
       "FACILITIES#COMFORT                 132\n",
       "FOOD&DRINKS#PRICES                 118\n",
       "HOTEL#MISCELLANEOUS                108\n",
       "ROOM_AMENITIES#COMFORT             100\n",
       "ROOM_AMENITIES#CLEANLINESS          89\n",
       "FACILITIES#PRICES                   53\n",
       "FACILITIES#MISCELLANEOUS            33\n",
       "FOOD&DRINKS#MISCELLANEOUS           13\n",
       "ROOMS#MISCELLANEOUS                  6\n",
       "ROOM_AMENITIES#MISCELLANEOUS         3\n",
       "ROOM_AMENITIES#PRICES                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.aspect_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "positive    10229\n",
       "negative     3155\n",
       "neutral       570\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N·ªôi th·∫•t ph√≤ng ƒë·∫ßy ƒë·ªß v√† ƒë∆∞·ª£c chu·∫©n b·ªã t·ªët. C√≥ d·ªçn ph√≤ng h√†ng ng√†y. Nh√¢n vi√™n d·ªçn d·∫πp v√† l·ªÖ t√¢n nhi·ªát t√¨nh. V·ªã tr√≠ g·∫ßn bi·ªÉn. Ph√≤ng h∆°i nh·ªè. Kh√°ch s·∫°n c√≥ t·∫ßm nh√¨n ra kh√¥ng ƒë∆∞·ª£c ƒë·∫πp l·∫Øm. Ti·ªÅn thu√™ xe do kh√°ch san li√™n h·ªá h∆°i m·∫Øc v√† kh√¥ng c√≥ nhi·ªÅu xe ƒë·ªÉ ch·ªçn. N∆∞·ªõc ch·∫£y y·∫øu ·ªü v√≤i sen. Bu·ªïi s√°ng h∆°i √≠t m√≥n.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.text.iloc[1584]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hi·∫øu\" == \"hi·∫øu\", \"hi·∫øu\" == \"hi√™√∫\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source code: https://colab.research.google.com/github/nguyenvanhieuvn/text-classification-tutorial/blob/master/text_classification_tutorial.ipynb#scrollTo=Koy7eu1dMwxn\n",
    "import regex as re\n",
    "\n",
    "uniChars = \"√†√°·∫£√£·∫°√¢·∫ß·∫•·∫©·∫´·∫≠ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªáƒë√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµ√Ä√Å·∫¢√É·∫†√Ç·∫¶·∫§·∫®·∫™·∫¨ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂√à√â·∫∫·∫º·∫∏√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜƒê√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªí·ªê·ªî·ªñ·ªò∆†·ªú·ªö·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª™·ª®·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥√ÇƒÇƒê√î∆†∆Ø\"\n",
    "unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
    "\n",
    "def loaddicchar():\n",
    "    dic = {}\n",
    "    char1252 = 'aÃÄ|aÃÅ|aÃâ|aÃÉ|aÃ£|√¢ÃÄ|√¢ÃÅ|√¢Ãâ|√¢ÃÉ|√¢Ã£|ƒÉÃÄ|ƒÉÃÅ|ƒÉÃâ|ƒÉÃÉ|ƒÉÃ£|eÃÄ|eÃÅ|eÃâ|eÃÉ|eÃ£|√™ÃÄ|√™ÃÅ|√™Ãâ|√™ÃÉ|√™Ã£|iÃÄ|iÃÅ|iÃâ|iÃÉ|iÃ£|oÃÄ|oÃÅ|oÃâ|oÃÉ|oÃ£|√¥ÃÄ|√¥ÃÅ|√¥Ãâ|√¥ÃÉ|√¥Ã£|∆°ÃÄ|∆°ÃÅ|∆°Ãâ|∆°ÃÉ|∆°Ã£|uÃÄ|uÃÅ|uÃâ|uÃÉ|uÃ£|∆∞ÃÄ|∆∞ÃÅ|∆∞Ãâ|∆∞ÃÉ|∆∞Ã£|yÃÄ|yÃÅ|yÃâ|yÃÉ|yÃ£|AÃÄ|AÃÅ|AÃâ|AÃÉ|AÃ£|√ÇÃÄ|√ÇÃÅ|√ÇÃâ|√ÇÃÉ|√ÇÃ£|ƒÇÃÄ|ƒÇÃÅ|ƒÇÃâ|ƒÇÃÉ|ƒÇÃ£|EÃÄ|EÃÅ|EÃâ|EÃÉ|EÃ£|√äÃÄ|√äÃÅ|√äÃâ|√äÃÉ|√äÃ£|IÃÄ|IÃÅ|IÃâ|IÃÉ|IÃ£|OÃÄ|OÃÅ|OÃâ|OÃÉ|OÃ£|√îÃÄ|√îÃÅ|√îÃâ|√îÃÉ|√îÃ£|∆†ÃÄ|∆†ÃÅ|∆†Ãâ|∆†ÃÉ|∆†Ã£|UÃÄ|UÃÅ|UÃâ|UÃÉ|UÃ£|∆ØÃÄ|∆ØÃÅ|∆ØÃâ|∆ØÃÉ|∆ØÃ£|YÃÄ|YÃÅ|YÃâ|YÃÉ|YÃ£'.split(\n",
    "        '|')\n",
    "    charutf8 = \"√†|√°|·∫£|√£|·∫°|·∫ß|·∫•|·∫©|·∫´|·∫≠|·∫±|·∫Ø|·∫≥|·∫µ|·∫∑|√®|√©|·∫ª|·∫Ω|·∫π|·ªÅ|·∫ø|·ªÉ|·ªÖ|·ªá|√¨|√≠|·ªâ|ƒ©|·ªã|√≤|√≥|·ªè|√µ|·ªç|·ªì|·ªë|·ªï|·ªó|·ªô|·ªù|·ªõ|·ªü|·ª°|·ª£|√π|√∫|·ªß|≈©|·ª•|·ª´|·ª©|·ª≠|·ªØ|·ª±|·ª≥|√Ω|·ª∑|·ªπ|·ªµ|√Ä|√Å|·∫¢|√É|·∫†|·∫¶|·∫§|·∫®|·∫™|·∫¨|·∫∞|·∫Æ|·∫≤|·∫¥|·∫∂|√à|√â|·∫∫|·∫º|·∫∏|·ªÄ|·∫æ|·ªÇ|·ªÑ|·ªÜ|√å|√ç|·ªà|ƒ®|·ªä|√í|√ì|·ªé|√ï|·ªå|·ªí|·ªê|·ªî|·ªñ|·ªò|·ªú|·ªö|·ªû|·ª†|·ª¢|√ô|√ö|·ª¶|≈®|·ª§|·ª™|·ª®|·ª¨|·ªÆ|·ª∞|·ª≤|√ù|·ª∂|·ª∏|·ª¥\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    "dicchar = loaddicchar()\n",
    "\n",
    "# H√†m chuy·ªÉn Unicode d·ª±ng s·∫µn v·ªÅ Unicde t·ªï h·ª£p (ph·ªï bi·∫øn h∆°n)\n",
    "def convert_unicode(txt):\n",
    "    return re.sub(\n",
    "        r'aÃÄ|aÃÅ|aÃâ|aÃÉ|aÃ£|√¢ÃÄ|√¢ÃÅ|√¢Ãâ|√¢ÃÉ|√¢Ã£|ƒÉÃÄ|ƒÉÃÅ|ƒÉÃâ|ƒÉÃÉ|ƒÉÃ£|eÃÄ|eÃÅ|eÃâ|eÃÉ|eÃ£|√™ÃÄ|√™ÃÅ|√™Ãâ|√™ÃÉ|√™Ã£|iÃÄ|iÃÅ|iÃâ|iÃÉ|iÃ£|oÃÄ|oÃÅ|oÃâ|oÃÉ|oÃ£|√¥ÃÄ|√¥ÃÅ|√¥Ãâ|√¥ÃÉ|√¥Ã£|∆°ÃÄ|∆°ÃÅ|∆°Ãâ|∆°ÃÉ|∆°Ã£|uÃÄ|uÃÅ|uÃâ|uÃÉ|uÃ£|∆∞ÃÄ|∆∞ÃÅ|∆∞Ãâ|∆∞ÃÉ|∆∞Ã£|yÃÄ|yÃÅ|yÃâ|yÃÉ|yÃ£|AÃÄ|AÃÅ|AÃâ|AÃÉ|AÃ£|√ÇÃÄ|√ÇÃÅ|√ÇÃâ|√ÇÃÉ|√ÇÃ£|ƒÇÃÄ|ƒÇÃÅ|ƒÇÃâ|ƒÇÃÉ|ƒÇÃ£|EÃÄ|EÃÅ|EÃâ|EÃÉ|EÃ£|√äÃÄ|√äÃÅ|√äÃâ|√äÃÉ|√äÃ£|IÃÄ|IÃÅ|IÃâ|IÃÉ|IÃ£|OÃÄ|OÃÅ|OÃâ|OÃÉ|OÃ£|√îÃÄ|√îÃÅ|√îÃâ|√îÃÉ|√îÃ£|∆†ÃÄ|∆†ÃÅ|∆†Ãâ|∆†ÃÉ|∆†Ã£|UÃÄ|UÃÅ|UÃâ|UÃÉ|UÃ£|∆ØÃÄ|∆ØÃÅ|∆ØÃâ|∆ØÃÉ|∆ØÃ£|YÃÄ|YÃÅ|YÃâ|YÃÉ|YÃ£',\n",
    "        lambda x: dicchar[x.group()], txt)\n",
    "\n",
    "bang_nguyen_am = [['a', '√†', '√°', '·∫£', '√£', '·∫°', 'a'],\n",
    "                  ['ƒÉ', '·∫±', '·∫Ø', '·∫≥', '·∫µ', '·∫∑', 'aw'],\n",
    "                  ['√¢', '·∫ß', '·∫•', '·∫©', '·∫´', '·∫≠', 'aa'],\n",
    "                  ['e', '√®', '√©', '·∫ª', '·∫Ω', '·∫π', 'e'],\n",
    "                  ['√™', '·ªÅ', '·∫ø', '·ªÉ', '·ªÖ', '·ªá', 'ee'],\n",
    "                  ['i', '√¨', '√≠', '·ªâ', 'ƒ©', '·ªã', 'i'],\n",
    "                  ['o', '√≤', '√≥', '·ªè', '√µ', '·ªç', 'o'],\n",
    "                  ['√¥', '·ªì', '·ªë', '·ªï', '·ªó', '·ªô', 'oo'],\n",
    "                  ['∆°', '·ªù', '·ªõ', '·ªü', '·ª°', '·ª£', 'ow'],\n",
    "                  ['u', '√π', '√∫', '·ªß', '≈©', '·ª•', 'u'],\n",
    "                  ['∆∞', '·ª´', '·ª©', '·ª≠', '·ªØ', '·ª±', 'uw'],\n",
    "                  ['y', '·ª≥', '√Ω', '·ª∑', '·ªπ', '·ªµ', 'y']]\n",
    "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
    "\n",
    "nguyen_am_to_ids = {}\n",
    "\n",
    "for i in range(len(bang_nguyen_am)):\n",
    "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
    "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
    "\n",
    "def chuan_hoa_dau_tu_tieng_viet(word):\n",
    "    if not is_valid_vietnam_word(word):\n",
    "        return word\n",
    "\n",
    "    chars = list(word)\n",
    "    dau_cau = 0\n",
    "    nguyen_am_index = []\n",
    "    qu_or_gi = False\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x == -1:\n",
    "            continue\n",
    "        elif x == 9:  # check qu\n",
    "            if index != 0 and chars[index - 1] == 'q':\n",
    "                chars[index] = 'u'\n",
    "                qu_or_gi = True\n",
    "        elif x == 5:  # check gi\n",
    "            if index != 0 and chars[index - 1] == 'g':\n",
    "                chars[index] = 'i'\n",
    "                qu_or_gi = True\n",
    "        if y != 0:\n",
    "            dau_cau = y\n",
    "            chars[index] = bang_nguyen_am[x][0]\n",
    "        if not qu_or_gi or index != 1:\n",
    "            nguyen_am_index.append(index)\n",
    "    if len(nguyen_am_index) < 2:\n",
    "        if qu_or_gi:\n",
    "            if len(chars) == 2:\n",
    "                x, y = nguyen_am_to_ids.get(chars[1])\n",
    "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
    "            else:\n",
    "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
    "                if x != -1:\n",
    "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
    "                else:\n",
    "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
    "            return ''.join(chars)\n",
    "        return word\n",
    "\n",
    "    for index in nguyen_am_index:\n",
    "        x, y = nguyen_am_to_ids[chars[index]]\n",
    "        if x == 4 or x == 8:  # √™, ∆°\n",
    "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
    "            # for index2 in nguyen_am_index:\n",
    "            #     if index2 != index:\n",
    "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
    "            #         chars[index2] = bang_nguyen_am[x][0]\n",
    "            return ''.join(chars)\n",
    "\n",
    "    if len(nguyen_am_index) == 2:\n",
    "        if nguyen_am_index[-1] == len(chars) - 1:\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
    "        else:\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "    else:\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
    "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
    "    return ''.join(chars)\n",
    "\n",
    "\n",
    "def is_valid_vietnam_word(word):\n",
    "    chars = list(word)\n",
    "    nguyen_am_index = -1\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x != -1:\n",
    "            if nguyen_am_index == -1:\n",
    "                nguyen_am_index = index\n",
    "            else:\n",
    "                if index - nguyen_am_index != 1:\n",
    "                    return False\n",
    "                nguyen_am_index = index\n",
    "    return True\n",
    "\n",
    "\n",
    "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
    "    \"\"\"\n",
    "        Chuy·ªÉn c√¢u ti·∫øng vi·ªát v·ªÅ chu·∫©n g√µ d·∫•u ki·ªÉu c≈©.\n",
    "        :param sentence:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    for index, word in enumerate(words):\n",
    "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
    "        # print(cw)\n",
    "        if len(cw) == 3:\n",
    "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
    "        words[index] = ''.join(cw)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_html(txt):\n",
    "    return re.sub(r'<[^>]*>', '', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-23 09:54:00--  https://gist.githubusercontent.com/nguyenvanhieuvn/7d9441c10b3c2739499fc5a4d9ea06fb/raw/df939245b3e841b62af115be4dcb3516dadc9fc5/teencode.txt\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5656 (5,5K) [text/plain]\n",
      "Saving to: ‚Äòteencode.txt‚Äô\n",
      "\n",
      "teencode.txt        100%[===================>]   5,52K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-10-23 09:54:00 (6,58 MB/s) - ‚Äòteencode.txt‚Äô saved [5656/5656]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://gist.githubusercontent.com/nguyenvanhieuvn/7d9441c10b3c2739499fc5a4d9ea06fb/raw/df939245b3e841b62af115be4dcb3516dadc9fc5/teencode.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "replace_list = {\n",
    "    '√¥ k√™i': 'ok', 'okie': 'ok', 'o k√™': 'ok', 'okey': 'ok', '√¥k√™': 'ok', 'oki': 'ok', 'oke': 'ok', 'okay': 'ok', 'ok√™': 'ok',\n",
    "    'tks': 'c·∫£m ∆°n', 'thks': 'c·∫£m ∆°n', 'thanks': 'c·∫£m ∆°n', 'ths': 'c·∫£m ∆°n', 'thank': 'c·∫£m ∆°n',\n",
    "    'kg': 'kh√¥ng', 'not': 'kh√¥ng', 'k': 'kh√¥ng', 'kh': 'kh√¥ng', 'k√¥': 'kh√¥ng', 'hok': 'kh√¥ng', 'ko': 'kh√¥ng', 'khong': 'kh√¥ng', 'kp': 'kh√¥ng ph·∫£i',\n",
    "    'he he': 't√≠ch c·ª±c', 'hehe': 't√≠ch c·ª±c', 'hihi': 't√≠ch c·ª±c', 'haha': 't√≠ch c·ª±c', 'hjhj': 't√≠ch c·ª±c', 'thick': 't√≠ch c·ª±c',\n",
    "    'lol': 'ti√™u c·ª±c', 'cc': 'ti√™u c·ª±c', 'huhu': 'ti√™u c·ª±c', 'cute': 'd·ªÖ th∆∞∆°ng',\n",
    "     \n",
    "    'sz': 'c·ª°', 'size': 'c·ª°', \n",
    "    'wa': 'qu√°', 'w√°': 'qu√°', 'q√°': 'qu√°', \n",
    "    'ƒëx': 'ƒë∆∞·ª£c', 'dk': 'ƒë∆∞·ª£c', 'dc': 'ƒë∆∞·ª£c', 'ƒëk': 'ƒë∆∞·ª£c', 'ƒëc': 'ƒë∆∞·ª£c', \n",
    "    'vs': 'v·ªõi', 'j': 'g√¨', '‚Äú': ' ', 'time': 'th·ªùi gian', 'm': 'm√¨nh', 'mik': 'm√¨nh', 'r': 'r·ªìi', 'bjo': 'bao gi·ªù', 'very': 'r·∫•t',\n",
    "\n",
    "    'authentic': 'chu·∫©n ch√≠nh h√£ng', 'aut': 'chu·∫©n ch√≠nh h√£ng', 'auth': 'chu·∫©n ch√≠nh h√£ng', 'date': 'h·∫°n s·ª≠ d·ª•ng', 'hsd': 'h·∫°n s·ª≠ d·ª•ng', \n",
    "    'store': 'c·ª≠a h√†ng', 'sop': 'c·ª≠a h√†ng', 'shopE': 'c·ª≠a h√†ng', 'shop': 'c·ª≠a h√†ng', \n",
    "    'sp': 's·∫£n ph·∫©m', 'product': 's·∫£n ph·∫©m', 'h√†g': 'h√†ng', \n",
    "    'ship': 'giao h√†ng', 'delivery': 'giao h√†ng', 's√≠p': 'giao h√†ng', 'order': 'ƒë·∫∑t h√†ng',\n",
    "\n",
    "    'gud': 't·ªët', 'wel done': 't·ªët', 'good': 't·ªët', 'g√∫t': 't·ªët', 'tot': 't·ªët', 'nice': 't·ªët', 'perfect': 'r·∫•t t·ªët', \n",
    "    'quality': 'ch·∫•t l∆∞·ª£ng', 'ch·∫•t lg': 'ch·∫•t l∆∞·ª£ng', 'chat': 'ch·∫•t', 'excelent': 'ho√†n h·∫£o', 'bt': 'b√¨nh th∆∞·ªùng',\n",
    "    'sad': 't·ªá', 'por': 't·ªá', 'poor': 't·ªá', 'bad': 't·ªá', \n",
    "    'beautiful': 'ƒë·∫πp tuy·ªát v·ªùi', 'dep': 'ƒë·∫πp', \n",
    "    'xau': 'x·∫•u', 's·∫•u': 'x·∫•u', \n",
    "     \n",
    "    'thik': 'th√≠ch', 'iu': 'y√™u', 'fake': 'gi·∫£ m·∫°o', \n",
    "    'quickly': 'nhanh', 'quick': 'nhanh', 'fast': 'nhanh',\n",
    "    'fresh': 't∆∞∆°i', 'delicious': 'ngon',\n",
    "\n",
    "    'dt': 'ƒëi·ªán tho·∫°i', 'fb': 'facebook', 'face': 'facebook', 'ks': 'kh√°ch s·∫°n', 'nv': 'nh√¢n vi√™n',\n",
    "    'nt': 'nh·∫Øn tin', 'ib': 'nh·∫Øn tin', 'tl': 'tr·∫£ l·ªùi', 'trl': 'tr·∫£ l·ªùi', 'rep': 'tr·∫£ l·ªùi',\n",
    "    'fback': 'feedback', 'fedback': 'feedback',\n",
    "    'sd': 's·ª≠ d·ª•ng', 's√†i': 'x√†i', \n",
    "\n",
    "    '^_^': 't√≠ch c·ª±c', ':)': 't√≠ch c·ª±c', ':(': 'ti√™u c·ª±c',\n",
    "    '‚ù§Ô∏è': 't√≠ch c·ª±c', 'üëç': 't√≠ch c·ª±c', 'üéâ': 't√≠ch c·ª±c', 'üòÄ': 't√≠ch c·ª±c', 'üòç': 't√≠ch c·ª±c', 'üòÇ': 't√≠ch c·ª±c', 'ü§ó': 't√≠ch c·ª±c', 'üòô': 't√≠ch c·ª±c', 'üôÇ': 't√≠ch c·ª±c', \n",
    "    'üòî': 'ti√™u c·ª±c', 'üòì': 'ti√™u c·ª±c', \n",
    "    '‚≠ê': 'star', '*': 'star', 'üåü': 'star',\n",
    "}\n",
    "\n",
    "with open('teencode.txt', encoding='utf-8') as f:\n",
    "    for pair in f.readlines():\n",
    "        key, value = pair.split('\\t')\n",
    "        replace_list[key] = value.strip()\n",
    "\n",
    "\n",
    "def normalize_acronyms(text):\n",
    "    words = []\n",
    "    for word in text.strip().split():\n",
    "        # word = word.strip(string.punctuation)\n",
    "        if word.lower() not in replace_list.keys(): words.append(word)\n",
    "        else: words.append(replace_list[word.lower()])\n",
    "    return emoji.demojize(' '.join(words)) # Remove Emojis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"Nh√¢n vi√™n nhi·ªát t√¨nh Ph√≤ng s·∫°ch s·∫Ω N·∫øu c√≥ d·ªãp s·∫Ω quay l·∫°i üëçüëç\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_space_between_emojis(sentence):\n",
    "    result = []\n",
    "    for i in range(len(sentence) - 1):\n",
    "        result.append(sentence[i])\n",
    "        if emoji.emoji_count(sentence[i:i+2]) == 2:\n",
    "            result.append(' ')\n",
    "    result.append(sentence[-1])\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nh√¢n vi√™n nhi·ªát t√¨nh Ph√≤ng s·∫°ch s·∫Ω N·∫øu c√≥ d·ªãp s·∫Ω quay l·∫°i :thumbs_up::thumbs_up:'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_acronyms(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nh√¢n vi√™n nhi·ªát t√¨nh Ph√≤ng s·∫°ch s·∫Ω N·∫øu c√≥ d·ªãp s·∫Ω quay l·∫°i t√≠ch c·ª±c t√≠ch c·ª±c'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_acronyms(insert_space_between_emojis(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nh√¢n vi√™n nhi·ªát t√¨nh Ph√≤ng s·∫°ch s·∫Ω N·∫øu c√≥ d·ªãp s·∫Ω quay l·∫°i:thumbs_up: t√≠ch c·ª±c'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_acronyms(insert_space_between_emojis(\"Nh√¢n vi√™n nhi·ªát t√¨nh Ph√≤ng s·∫°ch s·∫Ω N·∫øu c√≥ d·ªãp s·∫Ω quay l·∫°iüëçüëç\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/trungtv/pyvi\n",
    "from pyvi import ViTokenizer, ViPosTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-23 09:54:00--  https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords-dash.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20475 (20K) [text/plain]\n",
      "Saving to: ‚Äòvietnamese-stopwords-dash.txt‚Äô\n",
      "\n",
      "vietnamese-stopword 100%[===================>]  20,00K  --.-KB/s    in 0,005s  \n",
      "\n",
      "2023-10-23 09:54:01 (3,57 MB/s) - ‚Äòvietnamese-stopwords-dash.txt‚Äô saved [20475/20475]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords-dash.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    with open('./vietnamese-stopwords-dash.txt', encoding='utf-8') as f:\n",
    "        stopwords = set([w.strip()for w in f])\n",
    "        \n",
    "    words = text.split()\n",
    "    filtered_words = [w for w in words if w not in stopwords]\n",
    "    \n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(document):\n",
    "    document = normalize_acronyms(insert_space_between_emojis(document))\n",
    "    # x√≥a html code\n",
    "    document = remove_html(document)\n",
    "    # chu·∫©n h√≥a unicode\n",
    "    document = convert_unicode(document)\n",
    "    # chu·∫©n h√≥a c√°ch g√µ d·∫•u ti·∫øng Vi·ªát\n",
    "    document = chuan_hoa_dau_cau_tieng_viet(document)\n",
    "    # t√°ch t·ª´\n",
    "    document = ViTokenizer.tokenize(document)\n",
    "    # ƒë∆∞a v·ªÅ lower\n",
    "    document = document.lower()\n",
    "    # x√≥a c√°c k√Ω t·ª± kh√¥ng c·∫ßn thi·∫øt\n",
    "    document = re.sub(r'[^\\s\\w√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√≠√¨·ªâƒ©·ªã√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë_]',' ',document)\n",
    "    # x√≥a kho·∫£ng tr·∫Øng th·ª´a\n",
    "    document = re.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nh√¢n_vi√™n nhi·ªát_t√¨nh ph√≤ng s·∫°ch_s·∫Ω n·∫øu c√≥ d·ªãp s·∫Ω quay l·∫°i t√≠ch_c·ª±c t√≠ch_c·ª±c'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = text_preprocess(sample)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13954/13954 [00:17<00:00, 806.46it/s] \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7111/7111 [00:05<00:00, 1390.05it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2584/2584 [00:02<00:00, 1211.92it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_train['cleaned_text'] = df_train.text.progress_apply(text_preprocess)\n",
    "df_val['cleaned_text'] = df_val.text.progress_apply(text_preprocess)\n",
    "df_test['cleaned_text'] = df_test.text.progress_apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3001/3001 [00:03<00:00, 971.81it/s] \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:01<00:00, 1837.31it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [00:00<00:00, 1475.54it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_aspect_train['cleaned_text'] = df_aspect_train.text.progress_apply(text_preprocess)\n",
    "df_aspect_val['cleaned_text'] = df_aspect_val.text.progress_apply(text_preprocess)\n",
    "df_aspect_test['cleaned_text'] = df_aspect_test.text.progress_apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'co view huong ho tay sach se nhan vien tan tinh'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.cleaned_text.iloc[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aspect term extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aspect_terms(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    doc = ViPosTagger.postagging(text)\n",
    "    aspect_terms = []\n",
    "    #N - Common noun Nc - Noun Classifier Ny - Noun abbreviation Nu - Unit noun Np - Proper noun X - Unknown\n",
    "    aspect_pos_patterns = [\"N\", \"Np\", \"Nc\", \"Ny\", \"X\", \"V\", \"A\"]\n",
    "    \n",
    "    for idx, pos_tag in enumerate(doc[1]):\n",
    "        if pos_tag in aspect_pos_patterns:\n",
    "            aspect_terms.append(doc[0][idx])\n",
    "            \n",
    "    return ' '.join(aspect_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nh√¢n_vi√™n nhi·ªát_t√¨nh ph√≤ng s·∫°ch_s·∫Ω c√≥ d·ªãp quay t√≠ch_c·ª±c t√≠ch_c·ª±c'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_aspect_terms(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3001/3001 [00:00<00:00, 3237.33it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:00<00:00, 6645.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [00:00<00:00, 5129.85it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_aspect_train['aspect_term'] = df_aspect_train.cleaned_text.progress_apply(extract_aspect_terms)\n",
    "df_aspect_val['aspect_term'] = df_aspect_val.cleaned_text.progress_apply(extract_aspect_terms)\n",
    "df_aspect_test['aspect_term'] = df_aspect_test.cleaned_text.progress_apply(extract_aspect_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aspect category detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Ph√≤ng ƒë·∫πp , s·∫°ch s·∫Ω v√† g·∫ßn bi·ªÉn . Nh√¢n vi√™n d·ªÖ th∆∞∆°ng . Ph√≤ng kh√¥ng c√≥ view bi·ªÉn nh∆∞ l√∫c ƒë·∫∑t , Tv hay m·∫•t c√°p .\"\n",
    "correct_aspect_cat = \"ROOMS#DESIGN&FEATURES, ROOMS#CLEANLINESS, LOCATION#GENERAL, SERVICE#GENERAL, ROOMS#GENERAL, ROOM_AMENITIES#DESIGN&FEATURES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_column_names(binary_list, column_names):\n",
    "    for i, value in enumerate(binary_list):\n",
    "        if value == 1:\n",
    "            print(column_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def multi_label_metrics(true_labels, predicted_labels):\n",
    "    # Calculate Hamming loss\n",
    "    hamming_loss_value = hamming_loss(true_labels, predicted_labels)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score using micro and macro averaging\n",
    "    precision_micro = precision_score(true_labels, predicted_labels, average='micro')\n",
    "    recall_micro = recall_score(true_labels, predicted_labels, average='micro')\n",
    "    f1_micro = f1_score(true_labels, predicted_labels, average='micro')\n",
    "\n",
    "    precision_macro = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    recall_macro = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    f1_macro = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        \"Hamming Loss\": hamming_loss_value,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Micro)\": precision_micro,\n",
    "        \"Recall (Micro)\": recall_micro,\n",
    "        \"F1 Score (Micro)\": f1_micro,\n",
    "        \"Precision (Macro)\": precision_macro,\n",
    "        \"Recall (Macro)\": recall_macro,\n",
    "        \"F1 Score (Macro)\": f1_macro\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aspect_train_base = df_aspect_train.drop(columns=['text', 'cleaned_text'])\n",
    "df_aspect_val_base = df_aspect_val.drop(columns=['text', 'cleaned_text'])\n",
    "df_aspect_test_base = df_aspect_test.drop(columns=['text', 'cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACILITIES#CLEANLINESS</th>\n",
       "      <th>FACILITIES#COMFORT</th>\n",
       "      <th>FACILITIES#DESIGN&amp;FEATURES</th>\n",
       "      <th>FACILITIES#GENERAL</th>\n",
       "      <th>FACILITIES#MISCELLANEOUS</th>\n",
       "      <th>FACILITIES#PRICES</th>\n",
       "      <th>FACILITIES#QUALITY</th>\n",
       "      <th>FOOD&amp;DRINKS#MISCELLANEOUS</th>\n",
       "      <th>FOOD&amp;DRINKS#PRICES</th>\n",
       "      <th>FOOD&amp;DRINKS#QUALITY</th>\n",
       "      <th>...</th>\n",
       "      <th>ROOMS#QUALITY</th>\n",
       "      <th>ROOM_AMENITIES#CLEANLINESS</th>\n",
       "      <th>ROOM_AMENITIES#COMFORT</th>\n",
       "      <th>ROOM_AMENITIES#DESIGN&amp;FEATURES</th>\n",
       "      <th>ROOM_AMENITIES#GENERAL</th>\n",
       "      <th>ROOM_AMENITIES#MISCELLANEOUS</th>\n",
       "      <th>ROOM_AMENITIES#PRICES</th>\n",
       "      <th>ROOM_AMENITIES#QUALITY</th>\n",
       "      <th>SERVICE#GENERAL</th>\n",
       "      <th>aspect_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>r·ªông_r√£i kh√°ch_s·∫°n v·∫Øng d·ªãch_v·ª• ch·∫•t_l∆∞·ª£ng cao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ƒë·ªãa_ƒëi·ªÉm thu·∫≠n_ti·ªán v√≤ng b√°n_k√≠nh nhi·ªÅu qu√°n ƒÉ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ph·ª•c_v·ª• view ƒë·∫πp v·ªã_tr√≠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thu·∫≠n_ti·ªán s·∫°ch_s·∫Ω vui_v·∫ª h√†i_l√≤ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>v·ªã_tr√≠ ƒë·∫πp c√≥ qu√°n bar view ƒë·∫πp nh√¢n_vi√™n th√¢n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FACILITIES#CLEANLINESS  FACILITIES#COMFORT  FACILITIES#DESIGN&FEATURES  \\\n",
       "0                     0.0                 0.0                         0.0   \n",
       "1                     0.0                 0.0                         0.0   \n",
       "2                     0.0                 0.0                         0.0   \n",
       "3                     0.0                 0.0                         0.0   \n",
       "4                     0.0                 0.0                         0.0   \n",
       "\n",
       "   FACILITIES#GENERAL  FACILITIES#MISCELLANEOUS  FACILITIES#PRICES  \\\n",
       "0                 0.0                       0.0                0.0   \n",
       "1                 0.0                       0.0                0.0   \n",
       "2                 0.0                       0.0                0.0   \n",
       "3                 0.0                       0.0                0.0   \n",
       "4                 1.0                       0.0                0.0   \n",
       "\n",
       "   FACILITIES#QUALITY  FOOD&DRINKS#MISCELLANEOUS  FOOD&DRINKS#PRICES  \\\n",
       "0                 0.0                        0.0                 0.0   \n",
       "1                 0.0                        0.0                 0.0   \n",
       "2                 0.0                        0.0                 0.0   \n",
       "3                 0.0                        0.0                 0.0   \n",
       "4                 0.0                        0.0                 0.0   \n",
       "\n",
       "   FOOD&DRINKS#QUALITY  ...  ROOMS#QUALITY  ROOM_AMENITIES#CLEANLINESS  \\\n",
       "0                  0.0  ...            0.0                         0.0   \n",
       "1                  0.0  ...            0.0                         0.0   \n",
       "2                  0.0  ...            0.0                         0.0   \n",
       "3                  0.0  ...            0.0                         0.0   \n",
       "4                  0.0  ...            0.0                         0.0   \n",
       "\n",
       "   ROOM_AMENITIES#COMFORT  ROOM_AMENITIES#DESIGN&FEATURES  \\\n",
       "0                     0.0                             0.0   \n",
       "1                     0.0                             0.0   \n",
       "2                     0.0                             0.0   \n",
       "3                     0.0                             0.0   \n",
       "4                     0.0                             0.0   \n",
       "\n",
       "   ROOM_AMENITIES#GENERAL  ROOM_AMENITIES#MISCELLANEOUS  \\\n",
       "0                     0.0                           0.0   \n",
       "1                     0.0                           0.0   \n",
       "2                     0.0                           0.0   \n",
       "3                     0.0                           0.0   \n",
       "4                     0.0                           0.0   \n",
       "\n",
       "   ROOM_AMENITIES#PRICES  ROOM_AMENITIES#QUALITY  SERVICE#GENERAL  \\\n",
       "0                    0.0                     0.0              0.0   \n",
       "1                    0.0                     0.0              0.0   \n",
       "2                    0.0                     0.0              1.0   \n",
       "3                    0.0                     0.0              1.0   \n",
       "4                    0.0                     0.0              1.0   \n",
       "\n",
       "                                         aspect_term  \n",
       "0  r·ªông_r√£i kh√°ch_s·∫°n v·∫Øng d·ªãch_v·ª• ch·∫•t_l∆∞·ª£ng cao...  \n",
       "1  ƒë·ªãa_ƒëi·ªÉm thu·∫≠n_ti·ªán v√≤ng b√°n_k√≠nh nhi·ªÅu qu√°n ƒÉ...  \n",
       "2                            ph·ª•c_v·ª• view ƒë·∫πp v·ªã_tr√≠  \n",
       "3                 thu·∫≠n_ti·ªán s·∫°ch_s·∫Ω vui_v·∫ª h√†i_l√≤ng  \n",
       "4  v·ªã_tr√≠ ƒë·∫πp c√≥ qu√°n bar view ƒë·∫πp nh√¢n_vi√™n th√¢n...  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aspect_train_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3001,), (3001, 34), (2000,), (2000, 34), (600,), (600, 34))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_aspect_train_base = df_aspect_train_base.aspect_term\n",
    "y_aspect_train = df_aspect_train_base.drop(columns=['aspect_term'])\n",
    "\n",
    "x_aspect_val_base = df_aspect_val_base.aspect_term\n",
    "y_aspect_val = df_aspect_val_base.drop(columns=['aspect_term'])\n",
    "\n",
    "x_aspect_test_base = df_aspect_test_base.aspect_term\n",
    "y_aspect_test = df_aspect_test_base.drop(columns=['aspect_term'])\n",
    "\n",
    "x_aspect_train_base.shape, y_aspect_train.shape, x_aspect_val_base.shape, y_aspect_val.shape, x_aspect_test_base.shape, y_aspect_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3001, 5560)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_base = TfidfVectorizer()\n",
    "x_aspect_train_vect = vectorizer_base.fit_transform(x_aspect_train_base)\n",
    "x_aspect_val_vect = vectorizer_base.transform(x_aspect_val_base)\n",
    "x_aspect_test_vect = vectorizer_base.transform(x_aspect_test_base)\n",
    "test_text = vectorizer_base.transform([extract_aspect_terms(text_preprocess(text))])\n",
    "\n",
    "x_aspect_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_base = MultiOutputClassifier(LogisticRegression()).fit(x_aspect_train_vect, y_aspect_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Hamming Loss: 0.06738930160534724\n",
      "Accuracy: 0.157947350883039\n",
      "Precision (Micro): 0.9303174024078803\n",
      "Recall (Micro): 0.5482691894216297\n",
      "F1 Score (Micro): 0.6899350649350648\n",
      "Precision (Macro): 0.6749370864842208\n",
      "Recall (Macro): 0.2508173063350151\n",
      "F1 Score (Macro): 0.3162240548105005\n",
      "\n",
      "\n",
      " validation\n",
      "Hamming Loss: 0.06551470588235295\n",
      "Accuracy: 0.1405\n",
      "Precision (Micro): 0.828875681030213\n",
      "Recall (Micro): 0.4706792293629588\n",
      "F1 Score (Micro): 0.6004125930576734\n",
      "Precision (Macro): 0.4356671256421353\n",
      "Recall (Macro): 0.19348742609514696\n",
      "F1 Score (Macro): 0.23804076933121465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_res = multi_label_metrics(y_aspect_train, clf_base.predict(x_aspect_train_vect))\n",
    "val_res = multi_label_metrics(y_aspect_val, clf_base.predict(x_aspect_val_vect))\n",
    "test_res = multi_label_metrics(y_aspect_test, clf_base.predict(x_aspect_test_vect))\n",
    "\n",
    "print(\"train\")\n",
    "for metric, value in train_res.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n\\n validation\")\n",
    "for metric, value in val_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test\n",
      "Hamming Loss: 0.07916666666666666\n",
      "Accuracy: 0.08\n",
      "Precision (Micro): 0.8419195483415667\n",
      "Recall (Micro): 0.461687306501548\n",
      "F1 Score (Micro): 0.5963509122719319\n",
      "Precision (Macro): 0.4958716621846244\n",
      "Recall (Macro): 0.20046229614435584\n",
      "F1 Score (Macro): 0.2478286742413716\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n test\") \n",
    "for metric, value in test_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCATION#GENERAL\n",
      "ROOMS#CLEANLINESS\n",
      "ROOMS#DESIGN&FEATURES\n",
      "SERVICE#GENERAL\n",
      "\n",
      " ROOMS#DESIGN&FEATURES, ROOMS#CLEANLINESS, LOCATION#GENERAL, SERVICE#GENERAL, ROOMS#GENERAL, ROOM_AMENITIES#DESIGN&FEATURES\n"
     ]
    }
   ],
   "source": [
    "print_column_names(clf_base.predict(test_text)[0], column_names)\n",
    "print(\"\\n\", correct_aspect_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "        FACILITIES#CLEANLINESS       1.00      0.20      0.33         5\n",
      "            FACILITIES#COMFORT       0.00      0.00      0.00        26\n",
      "    FACILITIES#DESIGN&FEATURES       1.00      0.11      0.19        65\n",
      "            FACILITIES#GENERAL       0.00      0.00      0.00        21\n",
      "      FACILITIES#MISCELLANEOUS       0.00      0.00      0.00         8\n",
      "             FACILITIES#PRICES       0.00      0.00      0.00        13\n",
      "            FACILITIES#QUALITY       1.00      0.08      0.15        51\n",
      "     FOOD&DRINKS#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "            FOOD&DRINKS#PRICES       0.00      0.00      0.00         9\n",
      "           FOOD&DRINKS#QUALITY       0.83      0.74      0.78       129\n",
      "     FOOD&DRINKS#STYLE&OPTIONS       0.80      0.59      0.68       124\n",
      "             HOTEL#CLEANLINESS       0.92      0.16      0.28        67\n",
      "                 HOTEL#COMFORT       0.64      0.41      0.50        94\n",
      "         HOTEL#DESIGN&FEATURES       0.64      0.25      0.36        85\n",
      "                 HOTEL#GENERAL       0.87      0.47      0.61       151\n",
      "           HOTEL#MISCELLANEOUS       0.00      0.00      0.00        68\n",
      "                  HOTEL#PRICES       0.76      0.35      0.48        71\n",
      "                 HOTEL#QUALITY       0.00      0.00      0.00        13\n",
      "              LOCATION#GENERAL       0.95      0.81      0.88       221\n",
      "             ROOMS#CLEANLINESS       0.74      0.52      0.61       200\n",
      "                 ROOMS#COMFORT       0.69      0.19      0.30        93\n",
      "         ROOMS#DESIGN&FEATURES       0.74      0.57      0.64       198\n",
      "                 ROOMS#GENERAL       1.00      0.02      0.03        57\n",
      "           ROOMS#MISCELLANEOUS       0.00      0.00      0.00         4\n",
      "                  ROOMS#PRICES       0.60      0.10      0.18        29\n",
      "                 ROOMS#QUALITY       0.00      0.00      0.00        10\n",
      "    ROOM_AMENITIES#CLEANLINESS       0.00      0.00      0.00        46\n",
      "        ROOM_AMENITIES#COMFORT       1.00      0.03      0.06        68\n",
      "ROOM_AMENITIES#DESIGN&FEATURES       0.83      0.13      0.23       144\n",
      "        ROOM_AMENITIES#GENERAL       0.43      0.09      0.15        32\n",
      "  ROOM_AMENITIES#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "         ROOM_AMENITIES#PRICES       0.00      0.00      0.00         1\n",
      "        ROOM_AMENITIES#QUALITY       0.50      0.02      0.03        59\n",
      "               SERVICE#GENERAL       0.94      0.97      0.95       416\n",
      "\n",
      "                     micro avg       0.84      0.46      0.60      2584\n",
      "                     macro avg       0.50      0.20      0.25      2584\n",
      "                  weighted avg       0.75      0.46      0.52      2584\n",
      "                   samples avg       0.81      0.50      0.58      2584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_aspect_test, clf_base.predict(x_aspect_test_vect), target_names=column_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 1: use cleaned text instead of aspect term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aspect_train_test1 = df_aspect_train.drop(columns=['text', 'aspect_term'])\n",
    "df_aspect_val_test1 = df_aspect_val.drop(columns=['text', 'aspect_term'])\n",
    "df_aspect_test_test1 = df_aspect_test.drop(columns=['text', 'aspect_term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3001,), (3001, 34), (2000,), (2000, 34), (600,), (600, 34))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_aspect_train_test1 = df_aspect_train_test1.cleaned_text\n",
    "\n",
    "x_aspect_val_test1 = df_aspect_val_test1.cleaned_text\n",
    "\n",
    "x_aspect_test_test1 = df_aspect_test_test1.cleaned_text\n",
    "\n",
    "x_aspect_train_test1.shape, y_aspect_train.shape, x_aspect_val_test1.shape, y_aspect_val.shape, x_aspect_test_test1.shape, y_aspect_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3001, 5973)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_test1 = TfidfVectorizer()\n",
    "x_aspect_train_vect = vectorizer_test1.fit_transform(x_aspect_train_test1)\n",
    "x_aspect_val_vect = vectorizer_test1.transform(x_aspect_val_test1)\n",
    "x_aspect_test_vect = vectorizer_test1.transform(x_aspect_test_test1)\n",
    "test_text = vectorizer_test1.transform([text_preprocess(text)])\n",
    "\n",
    "x_aspect_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_test1 = MultiOutputClassifier(LogisticRegression()).fit(x_aspect_train_vect, y_aspect_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Hamming Loss: 0.06798714154105494\n",
      "Accuracy: 0.15594801732755748\n",
      "Precision (Micro): 0.9327658524549717\n",
      "Recall (Micro): 0.541890632838816\n",
      "F1 Score (Micro): 0.6855251824652069\n",
      "Precision (Macro): 0.6251547623876699\n",
      "Recall (Macro): 0.24398417650027207\n",
      "F1 Score (Macro): 0.30736867951569463\n",
      "\n",
      "\n",
      " validation\n",
      "Hamming Loss: 0.06576470588235295\n",
      "Accuracy: 0.1415\n",
      "Precision (Micro): 0.8440677966101695\n",
      "Recall (Micro): 0.45521023765996343\n",
      "F1 Score (Micro): 0.5914489311163895\n",
      "Precision (Macro): 0.46312395951087926\n",
      "Recall (Macro): 0.1834275017794106\n",
      "F1 Score (Macro): 0.22916144316875897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_res = multi_label_metrics(y_aspect_train, clf_test1.predict(x_aspect_train_vect))\n",
    "val_res = multi_label_metrics(y_aspect_val, clf_test1.predict(x_aspect_val_vect))\n",
    "test_res = multi_label_metrics(y_aspect_test, clf_test1.predict(x_aspect_test_vect))\n",
    "\n",
    "print(\"train\")\n",
    "for metric, value in train_res.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n\\n validation\")\n",
    "for metric, value in val_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Hamming Loss: 0.07857843137254902\n",
      "Accuracy: 0.08833333333333333\n",
      "Precision (Micro): 0.851109520400859\n",
      "Recall (Micro): 0.4601393188854489\n",
      "F1 Score (Micro): 0.597337352424014\n",
      "Precision (Macro): 0.4958755062499653\n",
      "Recall (Macro): 0.19622292112615086\n",
      "F1 Score (Macro): 0.2435223215680511\n"
     ]
    }
   ],
   "source": [
    "print(\"test\") \n",
    "for metric, value in test_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCATION#GENERAL\n",
      "ROOMS#CLEANLINESS\n",
      "ROOMS#DESIGN&FEATURES\n",
      "SERVICE#GENERAL\n",
      "\n",
      " ROOMS#DESIGN&FEATURES, ROOMS#CLEANLINESS, LOCATION#GENERAL, SERVICE#GENERAL, ROOMS#GENERAL, ROOM_AMENITIES#DESIGN&FEATURES\n"
     ]
    }
   ],
   "source": [
    "print_column_names(clf_test1.predict(test_text)[0], column_names)\n",
    "print(\"\\n\", correct_aspect_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "        FACILITIES#CLEANLINESS       0.00      0.00      0.00         5\n",
      "            FACILITIES#COMFORT       0.00      0.00      0.00        26\n",
      "    FACILITIES#DESIGN&FEATURES       1.00      0.12      0.22        65\n",
      "            FACILITIES#GENERAL       1.00      0.05      0.09        21\n",
      "      FACILITIES#MISCELLANEOUS       0.00      0.00      0.00         8\n",
      "             FACILITIES#PRICES       0.00      0.00      0.00        13\n",
      "            FACILITIES#QUALITY       1.00      0.08      0.15        51\n",
      "     FOOD&DRINKS#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "            FOOD&DRINKS#PRICES       0.00      0.00      0.00         9\n",
      "           FOOD&DRINKS#QUALITY       0.84      0.71      0.77       129\n",
      "     FOOD&DRINKS#STYLE&OPTIONS       0.79      0.56      0.65       124\n",
      "             HOTEL#CLEANLINESS       0.92      0.16      0.28        67\n",
      "                 HOTEL#COMFORT       0.62      0.32      0.42        94\n",
      "         HOTEL#DESIGN&FEATURES       0.82      0.39      0.53        85\n",
      "                 HOTEL#GENERAL       0.87      0.58      0.70       151\n",
      "           HOTEL#MISCELLANEOUS       0.00      0.00      0.00        68\n",
      "                  HOTEL#PRICES       0.78      0.35      0.49        71\n",
      "                 HOTEL#QUALITY       0.00      0.00      0.00        13\n",
      "              LOCATION#GENERAL       0.95      0.78      0.86       221\n",
      "             ROOMS#CLEANLINESS       0.75      0.52      0.61       200\n",
      "                 ROOMS#COMFORT       0.80      0.17      0.28        93\n",
      "         ROOMS#DESIGN&FEATURES       0.75      0.54      0.63       198\n",
      "                 ROOMS#GENERAL       1.00      0.04      0.07        57\n",
      "           ROOMS#MISCELLANEOUS       0.00      0.00      0.00         4\n",
      "                  ROOMS#PRICES       0.60      0.10      0.18        29\n",
      "                 ROOMS#QUALITY       0.00      0.00      0.00        10\n",
      "    ROOM_AMENITIES#CLEANLINESS       0.00      0.00      0.00        46\n",
      "        ROOM_AMENITIES#COMFORT       1.00      0.03      0.06        68\n",
      "ROOM_AMENITIES#DESIGN&FEATURES       0.76      0.13      0.22       144\n",
      "        ROOM_AMENITIES#GENERAL       0.33      0.06      0.11        32\n",
      "  ROOM_AMENITIES#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "         ROOM_AMENITIES#PRICES       0.00      0.00      0.00         1\n",
      "        ROOM_AMENITIES#QUALITY       0.33      0.02      0.03        59\n",
      "               SERVICE#GENERAL       0.93      0.97      0.95       416\n",
      "\n",
      "                     micro avg       0.85      0.46      0.60      2584\n",
      "                     macro avg       0.50      0.20      0.24      2584\n",
      "                  weighted avg       0.76      0.46      0.52      2584\n",
      "                   samples avg       0.81      0.49      0.58      2584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_aspect_test, clf_test1.predict(x_aspect_test_vect), target_names=column_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 2: use phobert instead of tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test2.1: phobert + base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vinai/phobert-base': 256, 'vinai/phobert-large': 256}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "PRETRAINED_MODEL = 'vinai/phobert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode: [0, 218, 8, 649, 212, 956, 2413, 195, 5, 2]\n",
      "Decode: <s> T√¥i l√† sinh_vi√™n tr∆∞·ªùng ƒë·∫°i_h·ªçc C√¥ng_ngh·ªá th√¥ng_tin. </s>\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode('T√¥i l√† sinh_vi√™n tr∆∞·ªùng ƒë·∫°i_h·ªçc C√¥ng_ngh·ªá th√¥ng_tin .') # When use PhoBERT\n",
    "print('Encode:', tokens)\n",
    "print('Decode:', tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_aspect_train_vect = tokenizer.batch_encode_plus(x_aspect_train_base, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "x_aspect_val_vect = tokenizer.batch_encode_plus(x_aspect_val_base, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "x_aspect_test_vect = tokenizer.batch_encode_plus(x_aspect_test_base, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "test_text = tokenizer.batch_encode_plus([extract_aspect_terms(text_preprocess(text))], pad_to_max_length=True, max_length=256, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_aspect_train_vect.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf_test21 = MultiOutputClassifier(LogisticRegression()).fit(x_aspect_train_vect['input_ids'], y_aspect_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Hamming Loss: 0.11870552952937256\n",
      "Accuracy: 0.03365544818393869\n",
      "Precision (Micro): 0.6469742934695832\n",
      "Recall (Micro): 0.2904034974557443\n",
      "F1 Score (Micro): 0.4008705975464978\n",
      "Precision (Macro): 0.7023189482599674\n",
      "Recall (Macro): 0.2792163874996363\n",
      "F1 Score (Macro): 0.36663196156257827\n",
      "\n",
      "\n",
      " validation\n",
      "Hamming Loss: 0.10442647058823529\n",
      "Accuracy: 0.028\n",
      "Precision (Micro): 0.5017972681524083\n",
      "Recall (Micro): 0.1963155674307411\n",
      "F1 Score (Micro): 0.28221975133933086\n",
      "Precision (Macro): 0.1778037156766603\n",
      "Recall (Macro): 0.05760101450010319\n",
      "F1 Score (Macro): 0.07150117021487022\n"
     ]
    }
   ],
   "source": [
    "train_res = multi_label_metrics(y_aspect_train, clf_test21.predict(x_aspect_train_vect['input_ids']))\n",
    "val_res = multi_label_metrics(y_aspect_val, clf_test21.predict(x_aspect_val_vect['input_ids']))\n",
    "test_res = multi_label_metrics(y_aspect_test, clf_test21.predict(x_aspect_test_vect['input_ids']))\n",
    "\n",
    "print(\"train\")\n",
    "for metric, value in train_res.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n\\n validation\")\n",
    "for metric, value in val_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Hamming Loss: 0.1271078431372549\n",
      "Accuracy: 0.005\n",
      "Precision (Micro): 0.4957825679475164\n",
      "Recall (Micro): 0.20472136222910217\n",
      "F1 Score (Micro): 0.28978362092577375\n",
      "Precision (Macro): 0.1955801649929933\n",
      "Recall (Macro): 0.0724442084942529\n",
      "F1 Score (Macro): 0.09077881192497139\n"
     ]
    }
   ],
   "source": [
    "print(\"test\") \n",
    "for metric, value in test_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "        FACILITIES#CLEANLINESS       0.00      0.00      0.00         5\n",
      "            FACILITIES#COMFORT       0.11      0.04      0.06        26\n",
      "    FACILITIES#DESIGN&FEATURES       0.34      0.15      0.21        65\n",
      "            FACILITIES#GENERAL       0.00      0.00      0.00        21\n",
      "      FACILITIES#MISCELLANEOUS       0.00      0.00      0.00         8\n",
      "             FACILITIES#PRICES       0.00      0.00      0.00        13\n",
      "            FACILITIES#QUALITY       0.08      0.02      0.03        51\n",
      "     FOOD&DRINKS#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "            FOOD&DRINKS#PRICES       0.29      0.22      0.25         9\n",
      "           FOOD&DRINKS#QUALITY       0.20      0.05      0.08       129\n",
      "     FOOD&DRINKS#STYLE&OPTIONS       0.36      0.08      0.13       124\n",
      "             HOTEL#CLEANLINESS       0.00      0.00      0.00        67\n",
      "                 HOTEL#COMFORT       0.16      0.10      0.12        94\n",
      "         HOTEL#DESIGN&FEATURES       0.34      0.13      0.19        85\n",
      "                 HOTEL#GENERAL       0.39      0.19      0.26       151\n",
      "           HOTEL#MISCELLANEOUS       0.14      0.01      0.03        68\n",
      "                  HOTEL#PRICES       0.14      0.01      0.03        71\n",
      "                 HOTEL#QUALITY       0.00      0.00      0.00        13\n",
      "              LOCATION#GENERAL       0.59      0.19      0.29       221\n",
      "             ROOMS#CLEANLINESS       0.53      0.04      0.07       200\n",
      "                 ROOMS#COMFORT       0.30      0.03      0.06        93\n",
      "         ROOMS#DESIGN&FEATURES       0.36      0.05      0.09       198\n",
      "                 ROOMS#GENERAL       0.14      0.02      0.03        57\n",
      "           ROOMS#MISCELLANEOUS       0.00      0.00      0.00         4\n",
      "                  ROOMS#PRICES       0.33      0.10      0.16        29\n",
      "                 ROOMS#QUALITY       0.00      0.00      0.00        10\n",
      "    ROOM_AMENITIES#CLEANLINESS       0.00      0.00      0.00        46\n",
      "        ROOM_AMENITIES#COMFORT       0.00      0.00      0.00        68\n",
      "ROOM_AMENITIES#DESIGN&FEATURES       0.64      0.05      0.09       144\n",
      "        ROOM_AMENITIES#GENERAL       0.40      0.06      0.11        32\n",
      "  ROOM_AMENITIES#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "         ROOM_AMENITIES#PRICES       0.00      0.00      0.00         1\n",
      "        ROOM_AMENITIES#QUALITY       0.11      0.02      0.03        59\n",
      "               SERVICE#GENERAL       0.70      0.89      0.78       416\n",
      "\n",
      "                     micro avg       0.50      0.20      0.29      2584\n",
      "                     macro avg       0.20      0.07      0.09      2584\n",
      "                  weighted avg       0.38      0.20      0.22      2584\n",
      "                   samples avg       0.55      0.20      0.27      2584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_aspect_test, clf_test21.predict(x_aspect_test_vect['input_ids']), \n",
    "                            target_names=column_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE#GENERAL\n",
      "\n",
      " ROOMS#DESIGN&FEATURES, ROOMS#CLEANLINESS, LOCATION#GENERAL, SERVICE#GENERAL, ROOMS#GENERAL, ROOM_AMENITIES#DESIGN&FEATURES\n"
     ]
    }
   ],
   "source": [
    "print_column_names(clf_test21.predict(test_text['input_ids'])[0], column_names)\n",
    "print(\"\\n\", correct_aspect_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 2.2: phobert + test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_aspect_train_vect = tokenizer.batch_encode_plus(x_aspect_train_test1, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "x_aspect_val_vect = tokenizer.batch_encode_plus(x_aspect_val_test1, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "x_aspect_test_vect = tokenizer.batch_encode_plus(x_aspect_test_test1, pad_to_max_length=True, max_length=256, truncation=True)\n",
    "test_text = tokenizer.batch_encode_plus(text_preprocess(text), pad_to_max_length=True, max_length=256, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf_test22 = MultiOutputClassifier(LogisticRegression()).fit(x_aspect_train_vect['input_ids'], y_aspect_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Hamming Loss: 0.11596134621792736\n",
      "Accuracy: 0.052649116961012994\n",
      "Precision (Micro): 0.6552026928142837\n",
      "Recall (Micro): 0.320862896868057\n",
      "F1 Score (Micro): 0.4307707110555181\n",
      "Precision (Macro): 0.7177762116591748\n",
      "Recall (Macro): 0.34037816168390345\n",
      "F1 Score (Macro): 0.4267571083534116\n",
      "\n",
      "\n",
      " validation\n",
      "Hamming Loss: 0.10764705882352942\n",
      "Accuracy: 0.024\n",
      "Precision (Micro): 0.46485031954254963\n",
      "Recall (Micro): 0.1943467866685417\n",
      "F1 Score (Micro): 0.27409758032526776\n",
      "Precision (Macro): 0.17041034418872786\n",
      "Recall (Macro): 0.060102436833532426\n",
      "F1 Score (Macro): 0.07640368214177706\n"
     ]
    }
   ],
   "source": [
    "train_res = multi_label_metrics(y_aspect_train, clf_test22.predict(x_aspect_train_vect['input_ids']))\n",
    "val_res = multi_label_metrics(y_aspect_val, clf_test22.predict(x_aspect_val_vect['input_ids']))\n",
    "test_res = multi_label_metrics(y_aspect_test, clf_test22.predict(x_aspect_test_vect['input_ids']))\n",
    "\n",
    "\n",
    "print(\"train\")\n",
    "for metric, value in train_res.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n\\n validation\")\n",
    "for metric, value in val_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Hamming Loss: 0.13357843137254902\n",
      "Accuracy: 0.005\n",
      "Precision (Micro): 0.4354986276303751\n",
      "Recall (Micro): 0.18421052631578946\n",
      "F1 Score (Micro): 0.2589067174326897\n",
      "Precision (Macro): 0.16426088760140697\n",
      "Recall (Macro): 0.06199958692763727\n",
      "F1 Score (Macro): 0.0773191976277992\n"
     ]
    }
   ],
   "source": [
    "print(\"test\") \n",
    "for metric, value in test_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "        FACILITIES#CLEANLINESS       0.00      0.00      0.00         5\n",
      "            FACILITIES#COMFORT       0.12      0.04      0.06        26\n",
      "    FACILITIES#DESIGN&FEATURES       0.24      0.09      0.13        65\n",
      "            FACILITIES#GENERAL       0.00      0.00      0.00        21\n",
      "      FACILITIES#MISCELLANEOUS       0.00      0.00      0.00         8\n",
      "             FACILITIES#PRICES       0.11      0.08      0.09        13\n",
      "            FACILITIES#QUALITY       0.12      0.02      0.03        51\n",
      "     FOOD&DRINKS#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "            FOOD&DRINKS#PRICES       0.11      0.11      0.11         9\n",
      "           FOOD&DRINKS#QUALITY       0.19      0.03      0.05       129\n",
      "     FOOD&DRINKS#STYLE&OPTIONS       0.22      0.04      0.07       124\n",
      "             HOTEL#CLEANLINESS       0.00      0.00      0.00        67\n",
      "                 HOTEL#COMFORT       0.11      0.09      0.10        94\n",
      "         HOTEL#DESIGN&FEATURES       0.20      0.09      0.13        85\n",
      "                 HOTEL#GENERAL       0.32      0.19      0.24       151\n",
      "           HOTEL#MISCELLANEOUS       0.20      0.03      0.05        68\n",
      "                  HOTEL#PRICES       0.21      0.04      0.07        71\n",
      "                 HOTEL#QUALITY       0.00      0.00      0.00        13\n",
      "              LOCATION#GENERAL       0.52      0.17      0.25       221\n",
      "             ROOMS#CLEANLINESS       0.62      0.05      0.09       200\n",
      "                 ROOMS#COMFORT       0.08      0.01      0.02        93\n",
      "         ROOMS#DESIGN&FEATURES       0.51      0.10      0.16       198\n",
      "                 ROOMS#GENERAL       0.17      0.02      0.03        57\n",
      "           ROOMS#MISCELLANEOUS       0.00      0.00      0.00         4\n",
      "                  ROOMS#PRICES       0.08      0.03      0.05        29\n",
      "                 ROOMS#QUALITY       0.00      0.00      0.00        10\n",
      "    ROOM_AMENITIES#CLEANLINESS       0.11      0.02      0.04        46\n",
      "        ROOM_AMENITIES#COMFORT       0.22      0.03      0.05        68\n",
      "ROOM_AMENITIES#DESIGN&FEATURES       0.42      0.03      0.06       144\n",
      "        ROOM_AMENITIES#GENERAL       0.00      0.00      0.00        32\n",
      "  ROOM_AMENITIES#MISCELLANEOUS       0.00      0.00      0.00         3\n",
      "         ROOM_AMENITIES#PRICES       0.00      0.00      0.00         1\n",
      "        ROOM_AMENITIES#QUALITY       0.00      0.00      0.00        59\n",
      "               SERVICE#GENERAL       0.69      0.79      0.74       416\n",
      "\n",
      "                     micro avg       0.44      0.18      0.26      2584\n",
      "                     macro avg       0.16      0.06      0.08      2584\n",
      "                  weighted avg       0.35      0.18      0.20      2584\n",
      "                   samples avg       0.47      0.18      0.24      2584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_aspect_test, clf_test22.predict(x_aspect_test_vect['input_ids']), \n",
    "                            target_names=column_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE#GENERAL\n",
      "\n",
      " ROOMS#DESIGN&FEATURES, ROOMS#CLEANLINESS, LOCATION#GENERAL, SERVICE#GENERAL, ROOMS#GENERAL, ROOM_AMENITIES#DESIGN&FEATURES\n"
     ]
    }
   ],
   "source": [
    "print_column_names(clf_test21.predict(test_text['input_ids'])[0], column_names)\n",
    "print(\"\\n\", correct_aspect_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aspect category polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13954,), (7111,), (2584,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df_train.cleaned_text + ' ' + df_train.aspect_cat\n",
    "x_val  = df_val.cleaned_text + ' ' + df_val.aspect_cat\n",
    "x_test = df_test.cleaned_text + ' ' + df_test.aspect_cat\n",
    "\n",
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13954, 5987), (7111, 5987), (2584, 5987))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x_train_vect = vectorizer.fit_transform(x_train)\n",
    "x_val_vect = vectorizer.transform(x_val)\n",
    "x_test_vect = vectorizer.transform(x_test)\n",
    "\n",
    "x_train_vect.shape, x_val_vect.shape, x_test_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.fit_transform(df_train.polarity)\n",
    "y_val = le.transform(df_val.polarity)\n",
    "y_test = le.transform(df_test.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schnee/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = multi_label_metrics(y_train, model.predict(x_train_vect))\n",
    "val_res = multi_label_metrics(y_val, model.predict(x_val_vect))\n",
    "test_res = multi_label_metrics(y_test, model.predict(x_test_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Hamming Loss: 0.1411781568009173\n",
      "Accuracy: 0.8588218431990827\n",
      "Precision (Micro): 0.8588218431990827\n",
      "Recall (Micro): 0.8588218431990827\n",
      "F1 Score (Micro): 0.8588218431990827\n",
      "Precision (Macro): 0.7886508131095876\n",
      "Recall (Macro): 0.5635789518731895\n",
      "F1 Score (Macro): 0.5783081099259779\n",
      "\n",
      "\n",
      " validation\n",
      "Hamming Loss: 0.19969062016594008\n",
      "Accuracy: 0.8003093798340599\n",
      "Precision (Micro): 0.8003093798340599\n",
      "Recall (Micro): 0.8003093798340599\n",
      "F1 Score (Micro): 0.8003093798340599\n",
      "Precision (Macro): 0.6693081426517143\n",
      "Recall (Macro): 0.5057093111219956\n",
      "F1 Score (Macro): 0.5112747761585582\n"
     ]
    }
   ],
   "source": [
    "print(\"train\")\n",
    "for metric, value in train_res.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n\\n validation\")\n",
    "for metric, value in val_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test\n",
      "Hamming Loss: 0.21130030959752322\n",
      "Accuracy: 0.7886996904024768\n",
      "Precision (Micro): 0.7886996904024768\n",
      "Recall (Micro): 0.7886996904024768\n",
      "F1 Score (Micro): 0.7886996904024768\n",
      "Precision (Macro): 0.8291635019163109\n",
      "Recall (Macro): 0.5170095782090885\n",
      "F1 Score (Macro): 0.5132607392780288\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n test\") \n",
    "for metric, value in test_res.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.64      0.65       645\n",
      "     neutral       1.00      0.02      0.03       133\n",
      "    positive       0.83      0.90      0.86      1806\n",
      "\n",
      "    accuracy                           0.79      2584\n",
      "   macro avg       0.83      0.52      0.51      2584\n",
      "weighted avg       0.80      0.79      0.77      2584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(x_test_vect), target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_category(binary_list, column_names):\n",
    "    aspect_category = []\n",
    "    for i, value in enumerate(binary_list):\n",
    "        if value == 1:\n",
    "            aspect_category.append(column_names[i])\n",
    "    return aspect_category\n",
    "\n",
    "def print_res(text, cat_sen):\n",
    "    print(text)\n",
    "    for cat, sen in cat_sen.items():\n",
    "        print(f\"{{{cat}, {sen}}}\", end=' ')\n",
    "\n",
    "def absa_test1(text, acd, acd_vectorizer, model, model_vectorizer):\n",
    "    cleaned_text = text_preprocess(text)\n",
    "    cat_sen = {}\n",
    "    acd_vector = acd_vectorizer.transform([cleaned_text])\n",
    "    aspect_cand = get_aspect_category(acd.predict(acd_vector)[0], column_names)\n",
    "    for aspect in aspect_cand:\n",
    "        sentiment = le.inverse_transform(model.predict(model_vectorizer.transform([cleaned_text + ' ' + aspect])))[0]\n",
    "        cat_sen[aspect] = sentiment\n",
    "        \n",
    "    print_res(text, cat_sen)\n",
    "    \n",
    "def absa_base(text, acd, acd_vectorizer, model, model_vectorizer):\n",
    "    cleaned_text = text_preprocess(text)\n",
    "    aspect_text = extract_aspect_terms(cleaned_text)\n",
    "    cat_sen = {}\n",
    "    acd_vector = acd_vectorizer.transform([aspect_text])\n",
    "    aspect_cand = get_aspect_category(acd.predict(acd_vector)[0], column_names)\n",
    "    for aspect in aspect_cand:\n",
    "        sentiment = le.inverse_transform(model.predict(model_vectorizer.transform([cleaned_text + ' ' + aspect])))[0]\n",
    "        cat_sen[aspect] = sentiment\n",
    "        \n",
    "    print_res(text, cat_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R·ªông r√£i, s·∫°ch s·∫Ω. C√≥ ch·ªó trong ph√≤ng kh√¥ng b·∫Øt ƒë∆∞·ª£c wifi\n",
      "{FACILITIES#QUALITY, negative} {ROOMS#CLEANLINESS, positive} {ROOMS#DESIGN&FEATURES, positive} "
     ]
    }
   ],
   "source": [
    "usr_rev = \"R·ªông r√£i, s·∫°ch s·∫Ω. C√≥ ch·ªó trong ph√≤ng kh√¥ng b·∫Øt ƒë∆∞·ª£c wifi\"\n",
    "\n",
    "absa_test1(usr_rev, clf_test1, vectorizer_test1, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R·ªông r√£i, s·∫°ch s·∫Ω. C√≥ ch·ªó trong ph√≤ng kh√¥ng b·∫Øt ƒë∆∞·ª£c wifi\n",
      "{FACILITIES#QUALITY, negative} {ROOMS#CLEANLINESS, positive} {ROOMS#DESIGN&FEATURES, positive} "
     ]
    }
   ],
   "source": [
    "usr_rev = \"R·ªông r√£i, s·∫°ch s·∫Ω. C√≥ ch·ªó trong ph√≤ng kh√¥ng b·∫Øt ƒë∆∞·ª£c wifi\"\n",
    "\n",
    "absa_base(usr_rev, clf_base, vectorizer_base, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r·ªông_r√£i s·∫°ch_s·∫Ω c√≥ ch·ªó trong ph√≤ng kh√¥ng b·∫Øt ƒë∆∞·ª£c wifi'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocess(usr_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r·ªông_r√£i s·∫°ch_s·∫Ω c√≥ ch·ªó ph√≤ng b·∫Øt wifi'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_aspect_terms(text_preprocess(usr_rev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
